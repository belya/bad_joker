{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from scipy.stats import norm\n",
    "import nltk.data\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import reuters\n",
    "from nltk. corpus import gutenberg\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.layers import Input, Dense, Lambda, Layer, LSTM, Reshape, TimeDistributed, Dropout, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import gensim.downloader as api\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing code is data specific.  \n",
    "  \n",
    "It is an example of how one can use a pre-trained word2vec to embed sentences into a vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO train w2v model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = api.load('20-newsgroups')\n",
    "# info = api.info()  # show info about available models/datasets\n",
    "# word2vec_model = api.load(\"glove-twitter-100\")  # download the model and return as object ready for use\n",
    "# word2vec_model.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"shortjokes.csv\").set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = pd.read_csv(\"jokes_score_name_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1[\"Joke\"] = dataset_1[\"q\"] + \" \" + dataset_1[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = pd.read_csv(\"qajokes1.1.2.csv\")\n",
    "dataset_2[\"Joke\"] = dataset_2[\"Question\"] + \" \" + dataset_2[\"Answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = dataset[\"Joke\"].tolist() + dataset_1[\"Joke\"].tolist() + dataset_2[\"Joke\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return re.sub(\n",
    "        r\"[^\\w\\s']\", \n",
    "        \"\", \n",
    "        text\n",
    "    ).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_sentences = [preprocess_text(t) for t in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440099"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(preprocessed_sentences, size=100, window=10, workers=16, iter=100)\n",
    "# w2v_model = word2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phelps', 0.5148839950561523),\n",
       " (\"bolt's\", 0.5110259056091309),\n",
       " ('bloodbath', 0.45941269397735596),\n",
       " ('gust', 0.4141930341720581),\n",
       " ('nada', 0.4051152169704437),\n",
       " ('glimpse', 0.40208110213279724),\n",
       " ('key', 0.3946117162704468),\n",
       " ('ricocheted', 0.39381635189056396),\n",
       " ('lightning', 0.38503432273864746),\n",
       " ('binos', 0.38127273321151733)]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"bolt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = w2v_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing text from a variety of different sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 45000., 233729., 105550.,  20059.,   4429.,   2733.,   2216.,\n",
       "          2010.,   1910.,   1746.]),\n",
       " array([  1. ,  10.9,  20.8,  30.7,  40.6,  50.5,  60.4,  70.3,  80.2,\n",
       "         90.1, 100. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) + 1 for s in preprocessed_sentences if len(s) < 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No LSTM variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vectorize_sentence(sentence):\n",
    "#     concat_vector = []\n",
    "#     for word in sentence:\n",
    "#         try:\n",
    "#             concat_vector.append(w2v[word])\n",
    "#         except:\n",
    "#             return\n",
    "#     return [a for vector in concat_vector for a in vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized_sentences = [vectorize_sentence(sentence) for sentence in preprocessed_sentences if (len(sentence) < 15) & (len(sentence) > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized_sentences = [sentence for sentence in vectorized_sentences if sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing import sequence\n",
    "# vectorized_padded = sequence.pad_sequences(vectorized_sentences, maxlen=original_dim, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_vectorized_padded = (vectorized_padded - vectorized_padded.min()) / (vectorized_padded.max() - vectorized_padded.min())# + 0.01*np.random.randn(*normalized_vectorized_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_dims = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence(sentence):\n",
    "    concat_vector = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            concat_vector.append(w2v[word])\n",
    "        except:\n",
    "            return\n",
    "    return concat_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sentences = [vectorize_sentence(sentence) for sentence in preprocessed_sentences if (len(sentence) < 15) & (len(sentence) > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sentences = [sentence for sentence in vectorized_sentences if sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_padded = np.array([sentence + [[0] * 100] * (15 - len(sentence)) for sentence in vectorized_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.024572372436523"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_padded.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_padded_min = np.min(vectorized_padded)\n",
    "vectorized_padded_max = np.max(vectorized_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_vectorized_padded = vectorized_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dims = (15, 100)\n",
    "original_dim = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to shuffle the text vectors before splitting them into test and train samples.   \n",
    "  \n",
    "This is done to avoid clumping text with similar context and style in the dataset because it can confuse the neural network during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train, vectorized_test = train_test_split(normalized_vectorized_padded, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "def cut_dataset(dataset, batch_size):\n",
    "    rest = len(dataset) % batch_size\n",
    "    return dataset[:-rest]\n",
    "\n",
    "vectorized_train = cut_dataset(vectorized_train, batch_size)\n",
    "vectorized_test = cut_dataset(vectorized_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_vectorized_train = vectorized_train.reshape(-1, 1500)\n",
    "help_vectorized_test = vectorized_test.reshape(-1, 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get w2v embeddings for text with fixed length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Values was not in diapason\n",
    "2. LSTM usage in encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "lstm_dim = 100\n",
    "intermediate_dim = 100\n",
    "epochs = 200\n",
    "epsilon_std = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=original_dims)\n",
    "h = Bidirectional(LSTM(lstm_dim, return_sequences=False), merge_mode='concat')(x)\n",
    "h = Dense(intermediate_dim, activation='relu')(h)\n",
    "h = Dense(intermediate_dim, activation='relu')(h)\n",
    "h_mean = Dense(latent_dim, activation='relu')(h)\n",
    "z_mean = Dense(latent_dim)(h_mean)\n",
    "h_log_var = Dense(latent_dim, activation='relu')(h)\n",
    "z_log_var = Dense(latent_dim)(h_log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we instantiate these layers separately so as to reuse them later\n",
    "def custom_sigmoid(x):\n",
    "    return K.sigmoid(x) \n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid') \n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true, y_pred):\n",
    "    xent_loss = K.sum(K.binary_crossentropy(y_pred, y_true), axis=-1)\n",
    "    kl_loss = 0.5 * K.sum(K.square(z_mean) + K.exp(z_log_var) - 1. - z_log_var, axis=-1)\n",
    "    return xent_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='adam', loss=vae_loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61000 samples, validate on 26000 samples\n",
      "Epoch 1/200\n",
      "61000/61000 [==============================] - 13s 217us/step - loss: 7482.4536 - acc: 0.0033 - val_loss: 7009.0840 - val_acc: 0.0014\n",
      "\n",
      "Epoch 00001: saving model to /tmp/model.h5\n",
      "Epoch 2/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6978.4911 - acc: 0.0068 - val_loss: 6914.4647 - val_acc: 0.0082\n",
      "\n",
      "Epoch 00002: saving model to /tmp/model.h5\n",
      "Epoch 3/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 6815.9899 - acc: 0.0026 - val_loss: 6708.4793 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00003: saving model to /tmp/model.h5\n",
      "Epoch 4/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 6667.3652 - acc: 0.0021 - val_loss: 6626.5005 - val_acc: 0.0025\n",
      "\n",
      "Epoch 00004: saving model to /tmp/model.h5\n",
      "Epoch 5/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6604.5412 - acc: 0.0033 - val_loss: 6577.2451 - val_acc: 0.0056\n",
      "\n",
      "Epoch 00005: saving model to /tmp/model.h5\n",
      "Epoch 6/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 6560.2625 - acc: 0.0045 - val_loss: 6531.2313 - val_acc: 0.0027\n",
      "\n",
      "Epoch 00006: saving model to /tmp/model.h5\n",
      "Epoch 7/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6512.6701 - acc: 0.0024 - val_loss: 6495.0926 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00007: saving model to /tmp/model.h5\n",
      "Epoch 8/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6484.5470 - acc: 0.0054 - val_loss: 6470.7022 - val_acc: 0.0100\n",
      "\n",
      "Epoch 00008: saving model to /tmp/model.h5\n",
      "Epoch 9/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 6458.3633 - acc: 0.0100 - val_loss: 6443.3848 - val_acc: 0.0176\n",
      "\n",
      "Epoch 00009: saving model to /tmp/model.h5\n",
      "Epoch 10/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 6426.2797 - acc: 0.0158 - val_loss: 6412.0877 - val_acc: 0.0220\n",
      "\n",
      "Epoch 00010: saving model to /tmp/model.h5\n",
      "Epoch 11/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6399.3647 - acc: 0.0251 - val_loss: 6390.7531 - val_acc: 0.0273\n",
      "\n",
      "Epoch 00011: saving model to /tmp/model.h5\n",
      "Epoch 12/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6379.6264 - acc: 0.0339 - val_loss: 6373.6374 - val_acc: 0.0400\n",
      "\n",
      "Epoch 00012: saving model to /tmp/model.h5\n",
      "Epoch 13/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6364.5110 - acc: 0.0414 - val_loss: 6361.1391 - val_acc: 0.0381\n",
      "\n",
      "Epoch 00013: saving model to /tmp/model.h5\n",
      "Epoch 14/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6346.2421 - acc: 0.0507 - val_loss: 6343.0605 - val_acc: 0.0511\n",
      "\n",
      "Epoch 00014: saving model to /tmp/model.h5\n",
      "Epoch 15/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6333.2162 - acc: 0.0583 - val_loss: 6334.0944 - val_acc: 0.0588\n",
      "\n",
      "Epoch 00015: saving model to /tmp/model.h5\n",
      "Epoch 16/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6321.5444 - acc: 0.0667 - val_loss: 6321.7485 - val_acc: 0.0718\n",
      "\n",
      "Epoch 00016: saving model to /tmp/model.h5\n",
      "Epoch 17/200\n",
      "61000/61000 [==============================] - 10s 158us/step - loss: 6309.5112 - acc: 0.0720 - val_loss: 6311.9824 - val_acc: 0.0743\n",
      "\n",
      "Epoch 00017: saving model to /tmp/model.h5\n",
      "Epoch 18/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 6298.4648 - acc: 0.0785 - val_loss: 6301.6274 - val_acc: 0.0811\n",
      "\n",
      "Epoch 00018: saving model to /tmp/model.h5\n",
      "Epoch 19/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6287.9596 - acc: 0.0812 - val_loss: 6292.8563 - val_acc: 0.0853\n",
      "\n",
      "Epoch 00019: saving model to /tmp/model.h5\n",
      "Epoch 20/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6278.0658 - acc: 0.0837 - val_loss: 6283.0341 - val_acc: 0.0822\n",
      "\n",
      "Epoch 00020: saving model to /tmp/model.h5\n",
      "Epoch 21/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6266.5978 - acc: 0.0880 - val_loss: 6269.8270 - val_acc: 0.0849\n",
      "\n",
      "Epoch 00021: saving model to /tmp/model.h5\n",
      "Epoch 22/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 6251.5767 - acc: 0.0917 - val_loss: 6256.3234 - val_acc: 0.0939\n",
      "\n",
      "Epoch 00022: saving model to /tmp/model.h5\n",
      "Epoch 23/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 6237.4255 - acc: 0.0963 - val_loss: 6244.5553 - val_acc: 0.0889\n",
      "\n",
      "Epoch 00023: saving model to /tmp/model.h5\n",
      "Epoch 24/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 6223.9875 - acc: 0.0979 - val_loss: 6232.9777 - val_acc: 0.0974\n",
      "\n",
      "Epoch 00024: saving model to /tmp/model.h5\n",
      "Epoch 25/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6212.1348 - acc: 0.1037 - val_loss: 6222.0263 - val_acc: 0.1082\n",
      "\n",
      "Epoch 00025: saving model to /tmp/model.h5\n",
      "Epoch 26/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 6201.8722 - acc: 0.1079 - val_loss: 6214.2549 - val_acc: 0.1050\n",
      "\n",
      "Epoch 00026: saving model to /tmp/model.h5\n",
      "Epoch 27/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6194.0838 - acc: 0.1094 - val_loss: 6210.0549 - val_acc: 0.1086\n",
      "\n",
      "Epoch 00027: saving model to /tmp/model.h5\n",
      "Epoch 28/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 6185.3439 - acc: 0.1122 - val_loss: 6199.6122 - val_acc: 0.1105\n",
      "\n",
      "Epoch 00028: saving model to /tmp/model.h5\n",
      "Epoch 29/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 6176.7685 - acc: 0.1150 - val_loss: 6190.4999 - val_acc: 0.1150\n",
      "\n",
      "Epoch 00029: saving model to /tmp/model.h5\n",
      "Epoch 30/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6166.1921 - acc: 0.1174 - val_loss: 6182.0119 - val_acc: 0.1078\n",
      "\n",
      "Epoch 00030: saving model to /tmp/model.h5\n",
      "Epoch 31/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6157.1661 - acc: 0.1214 - val_loss: 6173.5601 - val_acc: 0.1247\n",
      "\n",
      "Epoch 00031: saving model to /tmp/model.h5\n",
      "Epoch 32/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6148.0254 - acc: 0.1248 - val_loss: 6165.1447 - val_acc: 0.1249\n",
      "\n",
      "Epoch 00032: saving model to /tmp/model.h5\n",
      "Epoch 33/200\n",
      "61000/61000 [==============================] - 10s 157us/step - loss: 6139.8750 - acc: 0.1286 - val_loss: 6157.3532 - val_acc: 0.1266\n",
      "\n",
      "Epoch 00033: saving model to /tmp/model.h5\n",
      "Epoch 34/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 6131.6287 - acc: 0.1305 - val_loss: 6148.6738 - val_acc: 0.1333\n",
      "\n",
      "Epoch 00034: saving model to /tmp/model.h5\n",
      "Epoch 35/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 6122.2424 - acc: 0.1333 - val_loss: 6141.0977 - val_acc: 0.1344\n",
      "\n",
      "Epoch 00035: saving model to /tmp/model.h5\n",
      "Epoch 36/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 6114.8815 - acc: 0.1360 - val_loss: 6135.2589 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00036: saving model to /tmp/model.h5\n",
      "Epoch 37/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6107.7012 - acc: 0.1384 - val_loss: 6129.6376 - val_acc: 0.1398\n",
      "\n",
      "Epoch 00037: saving model to /tmp/model.h5\n",
      "Epoch 38/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 6101.3691 - acc: 0.1396 - val_loss: 6123.9478 - val_acc: 0.1369\n",
      "\n",
      "Epoch 00038: saving model to /tmp/model.h5\n",
      "Epoch 39/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 6095.3114 - acc: 0.1402 - val_loss: 6117.9340 - val_acc: 0.1406\n",
      "\n",
      "Epoch 00039: saving model to /tmp/model.h5\n",
      "Epoch 40/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 6088.6112 - acc: 0.1408 - val_loss: 6111.9811 - val_acc: 0.1415\n",
      "\n",
      "Epoch 00040: saving model to /tmp/model.h5\n",
      "Epoch 41/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6080.5465 - acc: 0.1418 - val_loss: 6104.5913 - val_acc: 0.1410\n",
      "\n",
      "Epoch 00041: saving model to /tmp/model.h5\n",
      "Epoch 42/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6075.0271 - acc: 0.1431 - val_loss: 6101.6643 - val_acc: 0.1442\n",
      "\n",
      "Epoch 00042: saving model to /tmp/model.h5\n",
      "Epoch 43/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 6069.1269 - acc: 0.1438 - val_loss: 6095.7082 - val_acc: 0.1425\n",
      "\n",
      "Epoch 00043: saving model to /tmp/model.h5\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61000/61000 [==============================] - 9s 152us/step - loss: 6061.8640 - acc: 0.1439 - val_loss: 6089.3466 - val_acc: 0.1428\n",
      "\n",
      "Epoch 00044: saving model to /tmp/model.h5\n",
      "Epoch 45/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 6056.2081 - acc: 0.1447 - val_loss: 6084.3554 - val_acc: 0.1452\n",
      "\n",
      "Epoch 00045: saving model to /tmp/model.h5\n",
      "Epoch 46/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6050.3209 - acc: 0.1458 - val_loss: 6078.1991 - val_acc: 0.1456\n",
      "\n",
      "Epoch 00046: saving model to /tmp/model.h5\n",
      "Epoch 47/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 6043.5149 - acc: 0.1464 - val_loss: 6072.8964 - val_acc: 0.1463\n",
      "\n",
      "Epoch 00047: saving model to /tmp/model.h5\n",
      "Epoch 48/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6038.1277 - acc: 0.1462 - val_loss: 6069.0397 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00048: saving model to /tmp/model.h5\n",
      "Epoch 49/200\n",
      "61000/61000 [==============================] - 10s 157us/step - loss: 6032.6170 - acc: 0.1466 - val_loss: 6065.4963 - val_acc: 0.1468\n",
      "\n",
      "Epoch 00049: saving model to /tmp/model.h5\n",
      "Epoch 50/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 6027.9556 - acc: 0.1473 - val_loss: 6060.6432 - val_acc: 0.1469\n",
      "\n",
      "Epoch 00050: saving model to /tmp/model.h5\n",
      "Epoch 51/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 6024.1283 - acc: 0.1474 - val_loss: 6058.2753 - val_acc: 0.1473\n",
      "\n",
      "Epoch 00051: saving model to /tmp/model.h5\n",
      "Epoch 52/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6019.0047 - acc: 0.1482 - val_loss: 6053.3426 - val_acc: 0.1474\n",
      "\n",
      "Epoch 00052: saving model to /tmp/model.h5\n",
      "Epoch 53/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6013.9473 - acc: 0.1483 - val_loss: 6048.5469 - val_acc: 0.1484\n",
      "\n",
      "Epoch 00053: saving model to /tmp/model.h5\n",
      "Epoch 54/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 6009.0596 - acc: 0.1489 - val_loss: 6044.0813 - val_acc: 0.1483\n",
      "\n",
      "Epoch 00054: saving model to /tmp/model.h5\n",
      "Epoch 55/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 6003.7774 - acc: 0.1488 - val_loss: 6038.8153 - val_acc: 0.1481\n",
      "\n",
      "Epoch 00055: saving model to /tmp/model.h5\n",
      "Epoch 56/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5997.8031 - acc: 0.1490 - val_loss: 6035.3161 - val_acc: 0.1488\n",
      "\n",
      "Epoch 00056: saving model to /tmp/model.h5\n",
      "Epoch 57/200\n",
      "61000/61000 [==============================] - 9s 150us/step - loss: 5993.6032 - acc: 0.1494 - val_loss: 6031.7804 - val_acc: 0.1482\n",
      "\n",
      "Epoch 00057: saving model to /tmp/model.h5\n",
      "Epoch 58/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5990.2043 - acc: 0.1493 - val_loss: 6030.1695 - val_acc: 0.1488\n",
      "\n",
      "Epoch 00058: saving model to /tmp/model.h5\n",
      "Epoch 59/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5986.0886 - acc: 0.1495 - val_loss: 6026.4867 - val_acc: 0.1487\n",
      "\n",
      "Epoch 00059: saving model to /tmp/model.h5\n",
      "Epoch 60/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5982.6851 - acc: 0.1495 - val_loss: 6022.4872 - val_acc: 0.1487\n",
      "\n",
      "Epoch 00060: saving model to /tmp/model.h5\n",
      "Epoch 61/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5978.8964 - acc: 0.1496 - val_loss: 6020.5559 - val_acc: 0.1485\n",
      "\n",
      "Epoch 00061: saving model to /tmp/model.h5\n",
      "Epoch 62/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5975.4097 - acc: 0.1495 - val_loss: 6017.8932 - val_acc: 0.1492\n",
      "\n",
      "Epoch 00062: saving model to /tmp/model.h5\n",
      "Epoch 63/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5971.6831 - acc: 0.1499 - val_loss: 6015.4865 - val_acc: 0.1490\n",
      "\n",
      "Epoch 00063: saving model to /tmp/model.h5\n",
      "Epoch 64/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5969.2121 - acc: 0.1500 - val_loss: 6012.2681 - val_acc: 0.1490\n",
      "\n",
      "Epoch 00064: saving model to /tmp/model.h5\n",
      "Epoch 65/200\n",
      "61000/61000 [==============================] - 10s 157us/step - loss: 5965.3480 - acc: 0.1499 - val_loss: 6010.1429 - val_acc: 0.1492\n",
      "\n",
      "Epoch 00065: saving model to /tmp/model.h5\n",
      "Epoch 66/200\n",
      "61000/61000 [==============================] - 10s 158us/step - loss: 5962.5734 - acc: 0.1501 - val_loss: 6007.4006 - val_acc: 0.1493\n",
      "\n",
      "Epoch 00066: saving model to /tmp/model.h5\n",
      "Epoch 67/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 5958.9400 - acc: 0.1502 - val_loss: 6003.7487 - val_acc: 0.1490\n",
      "\n",
      "Epoch 00067: saving model to /tmp/model.h5\n",
      "Epoch 68/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5954.8588 - acc: 0.1502 - val_loss: 6002.2658 - val_acc: 0.1493\n",
      "\n",
      "Epoch 00068: saving model to /tmp/model.h5\n",
      "Epoch 69/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5951.9372 - acc: 0.1504 - val_loss: 5998.6931 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00069: saving model to /tmp/model.h5\n",
      "Epoch 70/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5948.7949 - acc: 0.1505 - val_loss: 5998.0225 - val_acc: 0.1493\n",
      "\n",
      "Epoch 00070: saving model to /tmp/model.h5\n",
      "Epoch 71/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5946.4362 - acc: 0.1505 - val_loss: 5994.5076 - val_acc: 0.1494\n",
      "\n",
      "Epoch 00071: saving model to /tmp/model.h5\n",
      "Epoch 72/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 5942.5873 - acc: 0.1507 - val_loss: 5991.2470 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00072: saving model to /tmp/model.h5\n",
      "Epoch 73/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 5938.6966 - acc: 0.1507 - val_loss: 5988.1071 - val_acc: 0.1498\n",
      "\n",
      "Epoch 00073: saving model to /tmp/model.h5\n",
      "Epoch 74/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5935.2111 - acc: 0.1507 - val_loss: 5986.0768 - val_acc: 0.1497\n",
      "\n",
      "Epoch 00074: saving model to /tmp/model.h5\n",
      "Epoch 75/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5932.4057 - acc: 0.1508 - val_loss: 5983.5202 - val_acc: 0.1496\n",
      "\n",
      "Epoch 00075: saving model to /tmp/model.h5\n",
      "Epoch 76/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5930.2051 - acc: 0.1508 - val_loss: 5981.9049 - val_acc: 0.1497\n",
      "\n",
      "Epoch 00076: saving model to /tmp/model.h5\n",
      "Epoch 77/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 5926.5229 - acc: 0.1509 - val_loss: 5977.7946 - val_acc: 0.1496\n",
      "\n",
      "Epoch 00077: saving model to /tmp/model.h5\n",
      "Epoch 78/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5923.4545 - acc: 0.1509 - val_loss: 5976.6345 - val_acc: 0.1498\n",
      "\n",
      "Epoch 00078: saving model to /tmp/model.h5\n",
      "Epoch 79/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 5920.3901 - acc: 0.1509 - val_loss: 5973.9954 - val_acc: 0.1499\n",
      "\n",
      "Epoch 00079: saving model to /tmp/model.h5\n",
      "Epoch 80/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5918.1112 - acc: 0.1510 - val_loss: 5973.9188 - val_acc: 0.1500\n",
      "\n",
      "Epoch 00080: saving model to /tmp/model.h5\n",
      "Epoch 81/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 5915.6705 - acc: 0.1509 - val_loss: 5971.6353 - val_acc: 0.1500\n",
      "\n",
      "Epoch 00081: saving model to /tmp/model.h5\n",
      "Epoch 82/200\n",
      "61000/61000 [==============================] - 10s 157us/step - loss: 5913.0650 - acc: 0.1509 - val_loss: 5969.3496 - val_acc: 0.1499\n",
      "\n",
      "Epoch 00082: saving model to /tmp/model.h5\n",
      "Epoch 83/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 5911.0925 - acc: 0.1510 - val_loss: 5967.5452 - val_acc: 0.1501\n",
      "\n",
      "Epoch 00083: saving model to /tmp/model.h5\n",
      "Epoch 84/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5908.4651 - acc: 0.1510 - val_loss: 5964.7903 - val_acc: 0.1501\n",
      "\n",
      "Epoch 00084: saving model to /tmp/model.h5\n",
      "Epoch 85/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5906.4869 - acc: 0.1510 - val_loss: 5963.7871 - val_acc: 0.1500\n",
      "\n",
      "Epoch 00085: saving model to /tmp/model.h5\n",
      "Epoch 86/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5904.5878 - acc: 0.1510 - val_loss: 5961.2078 - val_acc: 0.1500\n",
      "\n",
      "Epoch 00086: saving model to /tmp/model.h5\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61000/61000 [==============================] - 9s 154us/step - loss: 5901.7844 - acc: 0.1510 - val_loss: 5958.6137 - val_acc: 0.1500\n",
      "\n",
      "Epoch 00087: saving model to /tmp/model.h5\n",
      "Epoch 88/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5899.2612 - acc: 0.1511 - val_loss: 5957.7933 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00088: saving model to /tmp/model.h5\n",
      "Epoch 89/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5896.2993 - acc: 0.1511 - val_loss: 5955.2818 - val_acc: 0.1501\n",
      "\n",
      "Epoch 00089: saving model to /tmp/model.h5\n",
      "Epoch 90/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5893.4533 - acc: 0.1511 - val_loss: 5953.6463 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00090: saving model to /tmp/model.h5\n",
      "Epoch 91/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5891.2176 - acc: 0.1511 - val_loss: 5951.9048 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00091: saving model to /tmp/model.h5\n",
      "Epoch 92/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 5888.7523 - acc: 0.1511 - val_loss: 5950.4013 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00092: saving model to /tmp/model.h5\n",
      "Epoch 93/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5886.1834 - acc: 0.1511 - val_loss: 5947.4390 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00093: saving model to /tmp/model.h5\n",
      "Epoch 94/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5882.8411 - acc: 0.1511 - val_loss: 5944.5389 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00094: saving model to /tmp/model.h5\n",
      "Epoch 95/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5880.8278 - acc: 0.1511 - val_loss: 5942.3839 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00095: saving model to /tmp/model.h5\n",
      "Epoch 96/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5877.4279 - acc: 0.1511 - val_loss: 5940.7703 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00096: saving model to /tmp/model.h5\n",
      "Epoch 97/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5874.0009 - acc: 0.1511 - val_loss: 5936.0284 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00097: saving model to /tmp/model.h5\n",
      "Epoch 98/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5870.9254 - acc: 0.1511 - val_loss: 5934.7147 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00098: saving model to /tmp/model.h5\n",
      "Epoch 99/200\n",
      "61000/61000 [==============================] - 10s 159us/step - loss: 5866.2821 - acc: 0.1511 - val_loss: 5929.4919 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00099: saving model to /tmp/model.h5\n",
      "Epoch 100/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5861.8944 - acc: 0.1511 - val_loss: 5925.8388 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00100: saving model to /tmp/model.h5\n",
      "Epoch 101/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5858.6142 - acc: 0.1511 - val_loss: 5925.0841 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00101: saving model to /tmp/model.h5\n",
      "Epoch 102/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5856.7534 - acc: 0.1511 - val_loss: 5922.7390 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00102: saving model to /tmp/model.h5\n",
      "Epoch 103/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5853.7976 - acc: 0.1511 - val_loss: 5920.4196 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00103: saving model to /tmp/model.h5\n",
      "Epoch 104/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5851.0239 - acc: 0.1511 - val_loss: 5918.5418 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00104: saving model to /tmp/model.h5\n",
      "Epoch 105/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5849.0228 - acc: 0.1511 - val_loss: 5916.6305 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00105: saving model to /tmp/model.h5\n",
      "Epoch 106/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5846.9761 - acc: 0.1511 - val_loss: 5914.9109 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00106: saving model to /tmp/model.h5\n",
      "Epoch 107/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 5844.6491 - acc: 0.1511 - val_loss: 5915.2982 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00107: saving model to /tmp/model.h5\n",
      "Epoch 108/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5842.6453 - acc: 0.1511 - val_loss: 5910.6542 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00108: saving model to /tmp/model.h5\n",
      "Epoch 109/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5839.5999 - acc: 0.1511 - val_loss: 5909.3701 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00109: saving model to /tmp/model.h5\n",
      "Epoch 110/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5837.0766 - acc: 0.1511 - val_loss: 5906.6926 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00110: saving model to /tmp/model.h5\n",
      "Epoch 111/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 5834.4831 - acc: 0.1511 - val_loss: 5904.9620 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00111: saving model to /tmp/model.h5\n",
      "Epoch 112/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5832.7183 - acc: 0.1511 - val_loss: 5904.3781 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00112: saving model to /tmp/model.h5\n",
      "Epoch 113/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5830.7979 - acc: 0.1511 - val_loss: 5902.4615 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00113: saving model to /tmp/model.h5\n",
      "Epoch 114/200\n",
      "61000/61000 [==============================] - 10s 158us/step - loss: 5828.8461 - acc: 0.1511 - val_loss: 5901.1078 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00114: saving model to /tmp/model.h5\n",
      "Epoch 115/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 5826.9865 - acc: 0.1511 - val_loss: 5899.9608 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00115: saving model to /tmp/model.h5\n",
      "Epoch 116/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5824.9103 - acc: 0.1511 - val_loss: 5897.9153 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00116: saving model to /tmp/model.h5\n",
      "Epoch 117/200\n",
      "61000/61000 [==============================] - 10s 157us/step - loss: 5823.3748 - acc: 0.1511 - val_loss: 5897.5617 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00117: saving model to /tmp/model.h5\n",
      "Epoch 118/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 5820.7486 - acc: 0.1511 - val_loss: 5893.6563 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00118: saving model to /tmp/model.h5\n",
      "Epoch 119/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5818.1316 - acc: 0.1511 - val_loss: 5892.6521 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00119: saving model to /tmp/model.h5\n",
      "Epoch 120/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5815.9814 - acc: 0.1511 - val_loss: 5890.0857 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00120: saving model to /tmp/model.h5\n",
      "Epoch 121/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5813.3289 - acc: 0.1511 - val_loss: 5888.5896 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00121: saving model to /tmp/model.h5\n",
      "Epoch 122/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5810.8416 - acc: 0.1511 - val_loss: 5885.5521 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00122: saving model to /tmp/model.h5\n",
      "Epoch 123/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5808.4614 - acc: 0.1511 - val_loss: 5883.9307 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00123: saving model to /tmp/model.h5\n",
      "Epoch 124/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 5806.2807 - acc: 0.1511 - val_loss: 5882.7356 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00124: saving model to /tmp/model.h5\n",
      "Epoch 125/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5804.2339 - acc: 0.1511 - val_loss: 5880.2938 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00125: saving model to /tmp/model.h5\n",
      "Epoch 126/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5802.0180 - acc: 0.1511 - val_loss: 5878.6067 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00126: saving model to /tmp/model.h5\n",
      "Epoch 127/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5799.6489 - acc: 0.1511 - val_loss: 5878.2197 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00127: saving model to /tmp/model.h5\n",
      "Epoch 128/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5797.4646 - acc: 0.1511 - val_loss: 5875.0040 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00128: saving model to /tmp/model.h5\n",
      "Epoch 129/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 5795.0384 - acc: 0.1511 - val_loss: 5872.9904 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00129: saving model to /tmp/model.h5\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61000/61000 [==============================] - 9s 155us/step - loss: 5792.0985 - acc: 0.1511 - val_loss: 5870.4695 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00130: saving model to /tmp/model.h5\n",
      "Epoch 131/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5789.3887 - acc: 0.1511 - val_loss: 5868.8295 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00131: saving model to /tmp/model.h5\n",
      "Epoch 132/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5787.1100 - acc: 0.1511 - val_loss: 5867.6909 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00132: saving model to /tmp/model.h5\n",
      "Epoch 133/200\n",
      "61000/61000 [==============================] - 9s 150us/step - loss: 5785.0555 - acc: 0.1511 - val_loss: 5864.3594 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00133: saving model to /tmp/model.h5\n",
      "Epoch 134/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5780.6153 - acc: 0.1511 - val_loss: 5860.9543 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00134: saving model to /tmp/model.h5\n",
      "Epoch 135/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5779.2085 - acc: 0.1511 - val_loss: 5858.8271 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00135: saving model to /tmp/model.h5\n",
      "Epoch 136/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5776.7968 - acc: 0.1511 - val_loss: 5857.1124 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00136: saving model to /tmp/model.h5\n",
      "Epoch 137/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5773.3637 - acc: 0.1511 - val_loss: 5855.2555 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00137: saving model to /tmp/model.h5\n",
      "Epoch 138/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5769.5213 - acc: 0.1511 - val_loss: 5852.5977 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00138: saving model to /tmp/model.h5\n",
      "Epoch 139/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5768.0329 - acc: 0.1511 - val_loss: 5850.2760 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00139: saving model to /tmp/model.h5\n",
      "Epoch 140/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5766.4402 - acc: 0.1511 - val_loss: 5848.7890 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00140: saving model to /tmp/model.h5\n",
      "Epoch 141/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5763.1342 - acc: 0.1511 - val_loss: 5845.0354 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00141: saving model to /tmp/model.h5\n",
      "Epoch 142/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5759.3948 - acc: 0.1511 - val_loss: 5842.9604 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00142: saving model to /tmp/model.h5\n",
      "Epoch 143/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5757.3504 - acc: 0.1511 - val_loss: 5841.5899 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00143: saving model to /tmp/model.h5\n",
      "Epoch 144/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5756.0211 - acc: 0.1511 - val_loss: 5840.3550 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00144: saving model to /tmp/model.h5\n",
      "Epoch 145/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5754.1191 - acc: 0.1511 - val_loss: 5839.3670 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00145: saving model to /tmp/model.h5\n",
      "Epoch 146/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5751.3184 - acc: 0.1511 - val_loss: 5836.6968 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00146: saving model to /tmp/model.h5\n",
      "Epoch 147/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5749.6160 - acc: 0.1511 - val_loss: 5834.3926 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00147: saving model to /tmp/model.h5\n",
      "Epoch 148/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5747.1214 - acc: 0.1511 - val_loss: 5833.4495 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00148: saving model to /tmp/model.h5\n",
      "Epoch 149/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5746.3447 - acc: 0.1511 - val_loss: 5832.5364 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00149: saving model to /tmp/model.h5\n",
      "Epoch 150/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5744.2500 - acc: 0.1511 - val_loss: 5830.9563 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00150: saving model to /tmp/model.h5\n",
      "Epoch 151/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5742.3521 - acc: 0.1511 - val_loss: 5829.2689 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00151: saving model to /tmp/model.h5\n",
      "Epoch 152/200\n",
      "61000/61000 [==============================] - 9s 150us/step - loss: 5740.3297 - acc: 0.1511 - val_loss: 5829.0172 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00152: saving model to /tmp/model.h5\n",
      "Epoch 153/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5739.3479 - acc: 0.1511 - val_loss: 5827.6510 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00153: saving model to /tmp/model.h5\n",
      "Epoch 154/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5736.5240 - acc: 0.1511 - val_loss: 5823.5851 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00154: saving model to /tmp/model.h5\n",
      "Epoch 155/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5733.4202 - acc: 0.1511 - val_loss: 5821.8149 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00155: saving model to /tmp/model.h5\n",
      "Epoch 156/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5731.5469 - acc: 0.1511 - val_loss: 5820.7333 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00156: saving model to /tmp/model.h5\n",
      "Epoch 157/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5729.6455 - acc: 0.1511 - val_loss: 5816.9079 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00157: saving model to /tmp/model.h5\n",
      "Epoch 158/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5726.4746 - acc: 0.1511 - val_loss: 5815.5799 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00158: saving model to /tmp/model.h5\n",
      "Epoch 159/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5723.2461 - acc: 0.1511 - val_loss: 5813.4699 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00159: saving model to /tmp/model.h5\n",
      "Epoch 160/200\n",
      "61000/61000 [==============================] - 10s 158us/step - loss: 5721.6640 - acc: 0.1511 - val_loss: 5811.3563 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00160: saving model to /tmp/model.h5\n",
      "Epoch 161/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5719.7356 - acc: 0.1511 - val_loss: 5809.2985 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00161: saving model to /tmp/model.h5\n",
      "Epoch 162/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 5717.3188 - acc: 0.1511 - val_loss: 5809.4281 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00162: saving model to /tmp/model.h5\n",
      "Epoch 163/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5715.6849 - acc: 0.1511 - val_loss: 5807.9889 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00163: saving model to /tmp/model.h5\n",
      "Epoch 164/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5714.7243 - acc: 0.1511 - val_loss: 5806.9885 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00164: saving model to /tmp/model.h5\n",
      "Epoch 165/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 5713.1300 - acc: 0.1511 - val_loss: 5805.0729 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00165: saving model to /tmp/model.h5\n",
      "Epoch 166/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5711.2416 - acc: 0.1511 - val_loss: 5804.5037 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00166: saving model to /tmp/model.h5\n",
      "Epoch 167/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 5708.2841 - acc: 0.1511 - val_loss: 5800.5198 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00167: saving model to /tmp/model.h5\n",
      "Epoch 168/200\n",
      "61000/61000 [==============================] - 10s 156us/step - loss: 5705.8241 - acc: 0.1511 - val_loss: 5799.8379 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00168: saving model to /tmp/model.h5\n",
      "Epoch 169/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5704.8024 - acc: 0.1511 - val_loss: 5797.6651 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00169: saving model to /tmp/model.h5\n",
      "Epoch 170/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5702.0947 - acc: 0.1511 - val_loss: 5797.0037 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00170: saving model to /tmp/model.h5\n",
      "Epoch 171/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5701.0546 - acc: 0.1511 - val_loss: 5795.7525 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00171: saving model to /tmp/model.h5\n",
      "Epoch 172/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 5698.9296 - acc: 0.1511 - val_loss: 5794.4074 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00172: saving model to /tmp/model.h5\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61000/61000 [==============================] - 9s 152us/step - loss: 5697.6331 - acc: 0.1511 - val_loss: 5792.5419 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00173: saving model to /tmp/model.h5\n",
      "Epoch 174/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5695.3853 - acc: 0.1511 - val_loss: 5792.0061 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00174: saving model to /tmp/model.h5\n",
      "Epoch 175/200\n",
      "61000/61000 [==============================] - 10s 157us/step - loss: 5694.1622 - acc: 0.1511 - val_loss: 5788.4963 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00175: saving model to /tmp/model.h5\n",
      "Epoch 176/200\n",
      "61000/61000 [==============================] - 10s 157us/step - loss: 5690.7874 - acc: 0.1511 - val_loss: 5787.6481 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00176: saving model to /tmp/model.h5\n",
      "Epoch 177/200\n",
      "61000/61000 [==============================] - 9s 156us/step - loss: 5688.9138 - acc: 0.1511 - val_loss: 5786.5314 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00177: saving model to /tmp/model.h5\n",
      "Epoch 178/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5685.9840 - acc: 0.1511 - val_loss: 5781.3079 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00178: saving model to /tmp/model.h5\n",
      "Epoch 179/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 5681.9717 - acc: 0.1511 - val_loss: 5778.2193 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00179: saving model to /tmp/model.h5\n",
      "Epoch 180/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5679.1294 - acc: 0.1511 - val_loss: 5776.4461 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00180: saving model to /tmp/model.h5\n",
      "Epoch 181/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 5676.6027 - acc: 0.1511 - val_loss: 5774.3782 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00181: saving model to /tmp/model.h5\n",
      "Epoch 182/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5674.4090 - acc: 0.1511 - val_loss: 5771.0614 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00182: saving model to /tmp/model.h5\n",
      "Epoch 183/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5671.8347 - acc: 0.1511 - val_loss: 5770.2011 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00183: saving model to /tmp/model.h5\n",
      "Epoch 184/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5669.8328 - acc: 0.1511 - val_loss: 5769.0645 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00184: saving model to /tmp/model.h5\n",
      "Epoch 185/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5668.5023 - acc: 0.1511 - val_loss: 5767.7594 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00185: saving model to /tmp/model.h5\n",
      "Epoch 186/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5667.1086 - acc: 0.1511 - val_loss: 5766.5360 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00186: saving model to /tmp/model.h5\n",
      "Epoch 187/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5665.4364 - acc: 0.1511 - val_loss: 5765.9352 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00187: saving model to /tmp/model.h5\n",
      "Epoch 188/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5664.9190 - acc: 0.1511 - val_loss: 5764.7389 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00188: saving model to /tmp/model.h5\n",
      "Epoch 189/200\n",
      "61000/61000 [==============================] - 9s 152us/step - loss: 5661.6741 - acc: 0.1511 - val_loss: 5760.7381 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00189: saving model to /tmp/model.h5\n",
      "Epoch 190/200\n",
      "61000/61000 [==============================] - 9s 151us/step - loss: 5657.6110 - acc: 0.1511 - val_loss: 5758.9979 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00190: saving model to /tmp/model.h5\n",
      "Epoch 191/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5654.8003 - acc: 0.1511 - val_loss: 5756.6297 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00191: saving model to /tmp/model.h5\n",
      "Epoch 192/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5652.9353 - acc: 0.1511 - val_loss: 5754.4089 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00192: saving model to /tmp/model.h5\n",
      "Epoch 193/200\n",
      "61000/61000 [==============================] - 9s 155us/step - loss: 5650.9623 - acc: 0.1511 - val_loss: 5753.0509 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00193: saving model to /tmp/model.h5\n",
      "Epoch 194/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5649.7590 - acc: 0.1511 - val_loss: 5752.7337 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00194: saving model to /tmp/model.h5\n",
      "Epoch 195/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5647.6863 - acc: 0.1511 - val_loss: 5750.1859 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00195: saving model to /tmp/model.h5\n",
      "Epoch 196/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5645.5081 - acc: 0.1511 - val_loss: 5748.4132 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00196: saving model to /tmp/model.h5\n",
      "Epoch 197/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5643.3343 - acc: 0.1511 - val_loss: 5747.2198 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00197: saving model to /tmp/model.h5\n",
      "Epoch 198/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5641.9412 - acc: 0.1511 - val_loss: 5745.9844 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00198: saving model to /tmp/model.h5\n",
      "Epoch 199/200\n",
      "61000/61000 [==============================] - 9s 153us/step - loss: 5639.7213 - acc: 0.1511 - val_loss: 5745.3198 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00199: saving model to /tmp/model.h5\n",
      "Epoch 200/200\n",
      "61000/61000 [==============================] - 9s 154us/step - loss: 5637.9991 - acc: 0.1511 - val_loss: 5743.7010 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00200: saving model to /tmp/model.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc801e93eb8>"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### checkpoint\n",
    "cp = [callbacks.ModelCheckpoint(filepath=\"/tmp/model.h5\", verbose=1)]\n",
    "\n",
    "#train\n",
    "vae.fit(vectorized_train, help_vectorized_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(vectorized_test, help_vectorized_test),\n",
    "        callbacks=cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# build a generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 15, 100)"
      ]
     },
     "execution_count": 1006,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_test[0:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_test[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.77534, 0.021861387)"
      ]
     },
     "execution_count": 1014,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = Model(x, z_log_var)\n",
    "np.min(test_model.predict(vectorized_test[0:10])), np.max(test_model.predict(vectorized_test[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text From Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some matrix magic\n",
    "def sent_parse(sentence, mat_shape):\n",
    "    data_concat = []\n",
    "    word_vecs = vectorize_sentences(sentence)\n",
    "    for x in word_vecs:\n",
    "        data_concat.append(list(itertools.chain.from_iterable(x)))\n",
    "    zero_matr = np.zeros(mat_shape)\n",
    "    zero_matr[0] = np.array(data_concat)\n",
    "    return zero_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentence_with_w2v(sent_vect):\n",
    "    sent_vect = sent_vect * (vectorized_padded.max() - vectorized_padded.min()) + vectorized_padded.min()\n",
    "    word_sent = ''\n",
    "    tocut = sent_vect\n",
    "    for i in range (int(len(sent_vect)/100)):\n",
    "        word_sent += w2v.most_similar(positive=[tocut[:100]], topn=1)[0][0]\n",
    "        word_sent += ' '\n",
    "        tocut = tocut[100:]\n",
    "    print(word_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: encoded sentence vector\n",
    "# output: encoded sentence vector in dataset with highest cosine similarity\n",
    "def find_similar_encoding(sent_vect):\n",
    "    all_cosine = []\n",
    "    for sent in sent_encoded:\n",
    "        result = 1 - spatial.distance.cosine(sent_vect, sent)\n",
    "        all_cosine.append(result)\n",
    "    data_array = np.array(all_cosine)\n",
    "    maximum = data_array.argsort()[-3:][::-1][1]\n",
    "    new_vec = sent_encoded[maximum]\n",
    "    return new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: two points, integer n\n",
    "# output: n equidistant points on the line between the input points (inclusive)\n",
    "def shortest_homology(point_one, point_two, num):\n",
    "    dist_vec = point_two - point_one\n",
    "    sample = np.linspace(0, 1, num, endpoint = True)\n",
    "    hom_sample = []\n",
    "    for s in sample:\n",
    "        hom_sample.append(point_one + s * dist_vec)\n",
    "    return hom_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: two written sentences, VAE batch-size, dimension of VAE input\n",
    "# output: the function embeds the sentences in latent-space, and then prints their generated text representations\n",
    "# along with the text representations of several points in between them\n",
    "def sent_2_sent(sent1,sent2, batch, dim):\n",
    "    a = sent_parse([sent1], (batch,dim))\n",
    "    b = sent_parse([sent2], (batch,dim))\n",
    "    encode_a = encoder.predict(a, batch_size = batch)\n",
    "    encode_b = encoder.predict(b, batch_size = batch)\n",
    "    test_hom = hom_shortest(encode_a[0], encode_b[0], 5)\n",
    "    \n",
    "    for point in test_hom:\n",
    "        p = generator.predict(np.array([point]))[0]\n",
    "        print_sentence(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing sentences from the training set and comparing them with the original will test whether the custom print function works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [vectorize_sentence(preprocess_text(\"zero should be less than or equal to zero\"))]\n",
    "# padded_sentences = sequence.pad_sequences(sentences, maxlen=original_dim, padding=\"post\", truncating=\"post\")\n",
    "padded_sentences = vectorized_train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder takes the training set of sentence vectors (concatenanted word vectors) and embeds them into a lower dimensional vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_encoded = encoder.predict(padded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder takes the list of latent dimensional encodings from above and turns them back into vectors of their original dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_decoded = generator.predict(sent_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in vectorized_train[0:10]:\n",
    "    print_sentence_with_w2v(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3.230534076690674,\n",
       "  1.7841397523880005,\n",
       "  0.33554771542549133,\n",
       "  -4.471125602722168,\n",
       "  -10.429625511169434,\n",
       "  -3.695082664489746,\n",
       "  -0.583594799041748,\n",
       "  -2.5402655601501465,\n",
       "  3.05374813079834,\n",
       "  1.3722996711730957,\n",
       "  3.656583547592163,\n",
       "  0.8342439532279968,\n",
       "  1.7185630798339844,\n",
       "  -5.148459434509277,\n",
       "  1.1783592700958252,\n",
       "  0.6966879963874817,\n",
       "  0.06443650275468826,\n",
       "  3.064058303833008,\n",
       "  5.935538291931152,\n",
       "  -0.010613851249217987,\n",
       "  1.6359413862228394,\n",
       "  2.384526014328003,\n",
       "  -3.332228422164917,\n",
       "  -2.9500839710235596,\n",
       "  -1.9641884565353394,\n",
       "  -2.8828322887420654,\n",
       "  0.1282566636800766,\n",
       "  4.546124458312988,\n",
       "  5.479730129241943,\n",
       "  1.7513734102249146,\n",
       "  1.0384042263031006,\n",
       "  -1.9057034254074097,\n",
       "  -1.1147444248199463,\n",
       "  -2.539559841156006,\n",
       "  -1.3884321451187134,\n",
       "  1.222303032875061,\n",
       "  5.743267059326172,\n",
       "  -0.8951510787010193,\n",
       "  -0.9526766538619995,\n",
       "  0.7061541676521301,\n",
       "  5.5933990478515625,\n",
       "  -4.280279159545898,\n",
       "  -7.2838664054870605,\n",
       "  -2.943571090698242,\n",
       "  -6.801851749420166,\n",
       "  -4.523406982421875,\n",
       "  1.4526540040969849,\n",
       "  4.607364177703857,\n",
       "  -3.6219122409820557,\n",
       "  2.496588706970215,\n",
       "  -3.5888073444366455,\n",
       "  0.9589131474494934,\n",
       "  3.4873647689819336,\n",
       "  1.2645443677902222,\n",
       "  -2.4187560081481934,\n",
       "  -4.746005535125732,\n",
       "  -3.1131138801574707,\n",
       "  3.7884392738342285,\n",
       "  3.005101442337036,\n",
       "  -1.4092258214950562,\n",
       "  2.4339821338653564,\n",
       "  -2.704282522201538,\n",
       "  1.6076257228851318,\n",
       "  5.2096147537231445,\n",
       "  -6.763061046600342,\n",
       "  -1.2148178815841675,\n",
       "  -1.6075513362884521,\n",
       "  -1.083599328994751,\n",
       "  -1.3392571210861206,\n",
       "  4.708255767822266,\n",
       "  -0.05124295502901077,\n",
       "  1.9248772859573364,\n",
       "  0.4634951949119568,\n",
       "  0.811869204044342,\n",
       "  5.069828510284424,\n",
       "  3.6725881099700928,\n",
       "  0.49462828040122986,\n",
       "  0.23351815342903137,\n",
       "  1.6974865198135376,\n",
       "  1.4233225584030151,\n",
       "  -4.058452129364014,\n",
       "  -5.225900173187256,\n",
       "  1.9404529333114624,\n",
       "  1.181511402130127,\n",
       "  0.2928043603897095,\n",
       "  0.35200822353363037,\n",
       "  -0.017008138820528984,\n",
       "  -0.939984142780304,\n",
       "  7.082186698913574,\n",
       "  6.630116939544678,\n",
       "  -4.59292459487915,\n",
       "  0.1468377262353897,\n",
       "  -4.763002872467041,\n",
       "  3.209498643875122,\n",
       "  -0.8208134174346924,\n",
       "  -4.652837753295898,\n",
       "  5.32594108581543,\n",
       "  -0.54928058385849,\n",
       "  -3.231973171234131,\n",
       "  1.6416447162628174],\n",
       " [-6.472095966339111,\n",
       "  -4.149787425994873,\n",
       "  9.081570625305176,\n",
       "  -2.6656384468078613,\n",
       "  -3.0854761600494385,\n",
       "  -1.7825900316238403,\n",
       "  -4.7416887283325195,\n",
       "  -1.046066164970398,\n",
       "  -0.8947409391403198,\n",
       "  1.030077576637268,\n",
       "  -0.45835426449775696,\n",
       "  -2.6896004676818848,\n",
       "  6.796546459197998,\n",
       "  0.8866065144538879,\n",
       "  1.4563971757888794,\n",
       "  -5.871591091156006,\n",
       "  -9.214095115661621,\n",
       "  -1.3279855251312256,\n",
       "  -3.807023286819458,\n",
       "  0.07551466673612595,\n",
       "  5.654322624206543,\n",
       "  -1.295122504234314,\n",
       "  4.604193210601807,\n",
       "  -3.164902925491333,\n",
       "  -1.3376871347427368,\n",
       "  1.05066978931427,\n",
       "  2.595621347427368,\n",
       "  -0.7095862627029419,\n",
       "  -1.4453531503677368,\n",
       "  0.26675844192504883,\n",
       "  3.0288941860198975,\n",
       "  -3.304385185241699,\n",
       "  11.161449432373047,\n",
       "  4.6831560134887695,\n",
       "  -0.08599980920553207,\n",
       "  1.8366535902023315,\n",
       "  -8.60055923461914,\n",
       "  -5.226597309112549,\n",
       "  2.562865734100342,\n",
       "  -0.7354900240898132,\n",
       "  6.207803249359131,\n",
       "  0.3574448823928833,\n",
       "  -0.9219357967376709,\n",
       "  4.106681823730469,\n",
       "  -5.329127311706543,\n",
       "  -0.9486612677574158,\n",
       "  -0.8590150475502014,\n",
       "  1.786798357963562,\n",
       "  -4.110156536102295,\n",
       "  -4.008227348327637,\n",
       "  -5.96985387802124,\n",
       "  0.6168292760848999,\n",
       "  2.000746488571167,\n",
       "  -1.2616291046142578,\n",
       "  1.4364460706710815,\n",
       "  5.643642902374268,\n",
       "  -3.8640215396881104,\n",
       "  -1.2378716468811035,\n",
       "  -5.771595001220703,\n",
       "  -1.3129340410232544,\n",
       "  -6.701383113861084,\n",
       "  -5.677984714508057,\n",
       "  -3.4005026817321777,\n",
       "  -11.948225021362305,\n",
       "  -2.846752405166626,\n",
       "  0.012421155348420143,\n",
       "  0.8433077335357666,\n",
       "  0.28114384412765503,\n",
       "  4.669904708862305,\n",
       "  8.168956756591797,\n",
       "  -2.6830103397369385,\n",
       "  -7.454861640930176,\n",
       "  0.4567812383174896,\n",
       "  -3.2379024028778076,\n",
       "  -2.2419943809509277,\n",
       "  -3.728339433670044,\n",
       "  -6.97312068939209,\n",
       "  7.4331865310668945,\n",
       "  5.60122537612915,\n",
       "  -1.3103086948394775,\n",
       "  -0.6498684287071228,\n",
       "  -0.8454477787017822,\n",
       "  -3.872343063354492,\n",
       "  -0.6749241948127747,\n",
       "  5.613226890563965,\n",
       "  5.820620059967041,\n",
       "  1.1128370761871338,\n",
       "  -2.406459093093872,\n",
       "  -3.2517354488372803,\n",
       "  -3.224919557571411,\n",
       "  -6.747446060180664,\n",
       "  -2.9672343730926514,\n",
       "  9.010320663452148,\n",
       "  -10.861099243164062,\n",
       "  3.9082536697387695,\n",
       "  -1.8285365104675293,\n",
       "  7.370645046234131,\n",
       "  -3.4518749713897705,\n",
       "  3.100869655609131,\n",
       "  -0.912315309047699],\n",
       " [-1.0472713708877563,\n",
       "  0.5988501906394958,\n",
       "  1.4367048740386963,\n",
       "  -3.720869541168213,\n",
       "  -1.9504868984222412,\n",
       "  0.5387944579124451,\n",
       "  2.8526015281677246,\n",
       "  1.725677490234375,\n",
       "  4.180934429168701,\n",
       "  0.38472989201545715,\n",
       "  0.08900505304336548,\n",
       "  2.0158512592315674,\n",
       "  0.8907453417778015,\n",
       "  -2.1325223445892334,\n",
       "  -0.50450599193573,\n",
       "  2.408179521560669,\n",
       "  1.0318365097045898,\n",
       "  -0.6411436796188354,\n",
       "  -3.8653554916381836,\n",
       "  -3.2827696800231934,\n",
       "  -1.1239327192306519,\n",
       "  2.2704973220825195,\n",
       "  4.726405620574951,\n",
       "  1.8203173875808716,\n",
       "  -1.0839136838912964,\n",
       "  1.760824203491211,\n",
       "  -0.5154547691345215,\n",
       "  -0.9128279089927673,\n",
       "  2.595756769180298,\n",
       "  -0.8977953791618347,\n",
       "  -2.981053590774536,\n",
       "  -0.6731727123260498,\n",
       "  1.746793270111084,\n",
       "  -2.3862991333007812,\n",
       "  -1.9776700735092163,\n",
       "  0.3205510079860687,\n",
       "  0.4315275549888611,\n",
       "  -1.7172895669937134,\n",
       "  2.708739757537842,\n",
       "  4.020386695861816,\n",
       "  -4.827291488647461,\n",
       "  0.5829427242279053,\n",
       "  -1.479034423828125,\n",
       "  -0.8734755516052246,\n",
       "  -1.8880877494812012,\n",
       "  -1.5404318571090698,\n",
       "  0.6330836415290833,\n",
       "  1.2416523694992065,\n",
       "  -1.352043628692627,\n",
       "  -0.241632342338562,\n",
       "  1.206762433052063,\n",
       "  -0.009800772182643414,\n",
       "  0.830964207649231,\n",
       "  0.17780844867229462,\n",
       "  0.41428321599960327,\n",
       "  -2.438905954360962,\n",
       "  1.0707310438156128,\n",
       "  1.0167070627212524,\n",
       "  4.0533447265625,\n",
       "  0.23702995479106903,\n",
       "  -1.1955772638320923,\n",
       "  1.3990119695663452,\n",
       "  1.1523445844650269,\n",
       "  -1.0407463312149048,\n",
       "  -0.8011511564254761,\n",
       "  -2.991899013519287,\n",
       "  -0.7374826669692993,\n",
       "  1.5655252933502197,\n",
       "  -0.20875464379787445,\n",
       "  -2.3279356956481934,\n",
       "  -1.551918387413025,\n",
       "  1.094468593597412,\n",
       "  3.173300266265869,\n",
       "  -1.2305206060409546,\n",
       "  1.2946484088897705,\n",
       "  -2.6893680095672607,\n",
       "  -2.202104330062866,\n",
       "  -0.4468783140182495,\n",
       "  0.8108262419700623,\n",
       "  -0.042680058628320694,\n",
       "  -2.0013415813446045,\n",
       "  -3.3341288566589355,\n",
       "  1.0709762573242188,\n",
       "  1.9105075597763062,\n",
       "  1.1463110446929932,\n",
       "  -2.6512205600738525,\n",
       "  -0.041337113827466965,\n",
       "  -4.075674533843994,\n",
       "  0.5787584185600281,\n",
       "  1.3132195472717285,\n",
       "  0.5555905103683472,\n",
       "  -1.5215014219284058,\n",
       "  0.17245618999004364,\n",
       "  -1.2015678882598877,\n",
       "  0.46543481945991516,\n",
       "  -1.8637769222259521,\n",
       "  -0.3255622684955597,\n",
       "  0.943586528301239,\n",
       "  -1.3780767917633057,\n",
       "  0.19930212199687958],\n",
       " [2.53503155708313,\n",
       "  -0.6958757638931274,\n",
       "  -0.8127261996269226,\n",
       "  4.433464527130127,\n",
       "  -4.732626438140869,\n",
       "  -5.2530131340026855,\n",
       "  -0.8195418119430542,\n",
       "  1.1934030055999756,\n",
       "  0.7382674217224121,\n",
       "  0.07029958814382553,\n",
       "  3.269247531890869,\n",
       "  -1.2382904291152954,\n",
       "  -8.800543785095215,\n",
       "  -3.550325393676758,\n",
       "  -6.010736465454102,\n",
       "  -0.8986160159111023,\n",
       "  -0.6210541725158691,\n",
       "  -1.6743053197860718,\n",
       "  5.535181522369385,\n",
       "  -7.4110283851623535,\n",
       "  0.756097674369812,\n",
       "  -1.5857394933700562,\n",
       "  1.557955265045166,\n",
       "  -0.37023910880088806,\n",
       "  -5.3705854415893555,\n",
       "  -1.4687867164611816,\n",
       "  -0.5945685505867004,\n",
       "  -2.337747812271118,\n",
       "  -0.0383722186088562,\n",
       "  4.118523120880127,\n",
       "  -0.14949534833431244,\n",
       "  -4.435544013977051,\n",
       "  -1.9837982654571533,\n",
       "  1.5888831615447998,\n",
       "  -0.3192857801914215,\n",
       "  -5.166118144989014,\n",
       "  2.0774567127227783,\n",
       "  3.3093950748443604,\n",
       "  -0.87857985496521,\n",
       "  0.6597266793251038,\n",
       "  -0.5219547748565674,\n",
       "  2.1410250663757324,\n",
       "  1.6189112663269043,\n",
       "  -0.06598589569330215,\n",
       "  -1.4106932878494263,\n",
       "  -0.5457888841629028,\n",
       "  -1.4402574300765991,\n",
       "  -1.0206190347671509,\n",
       "  3.121338129043579,\n",
       "  -1.3286001682281494,\n",
       "  -3.0471458435058594,\n",
       "  0.05284355580806732,\n",
       "  3.048814058303833,\n",
       "  1.0429069995880127,\n",
       "  -4.393375396728516,\n",
       "  -1.472401738166809,\n",
       "  2.8178484439849854,\n",
       "  -5.783240795135498,\n",
       "  -6.561883449554443,\n",
       "  0.3497343063354492,\n",
       "  1.016482949256897,\n",
       "  2.2072579860687256,\n",
       "  -3.1486265659332275,\n",
       "  3.591387987136841,\n",
       "  0.1912987381219864,\n",
       "  0.05944569408893585,\n",
       "  1.3040664196014404,\n",
       "  -0.12769074738025665,\n",
       "  3.7249820232391357,\n",
       "  -1.23685884475708,\n",
       "  1.9226382970809937,\n",
       "  -2.5036532878875732,\n",
       "  -0.8519741892814636,\n",
       "  -1.3642463684082031,\n",
       "  4.314640998840332,\n",
       "  -1.2447025775909424,\n",
       "  -0.2105492353439331,\n",
       "  -0.14537811279296875,\n",
       "  3.0031704902648926,\n",
       "  2.782439947128296,\n",
       "  -0.2291598618030548,\n",
       "  3.3467729091644287,\n",
       "  0.9931026101112366,\n",
       "  -0.30308324098587036,\n",
       "  2.5041511058807373,\n",
       "  4.263782501220703,\n",
       "  3.8232152462005615,\n",
       "  0.45936858654022217,\n",
       "  -2.0401082038879395,\n",
       "  1.2413735389709473,\n",
       "  -1.841384768486023,\n",
       "  3.06353497505188,\n",
       "  -0.34881287813186646,\n",
       "  2.7307519912719727,\n",
       "  3.5152065753936768,\n",
       "  2.07631254196167,\n",
       "  -2.0248937606811523,\n",
       "  -1.967078447341919,\n",
       "  0.20433309674263,\n",
       "  6.971105575561523],\n",
       " [-4.5198516845703125,\n",
       "  -4.62880277633667,\n",
       "  -0.04924177750945091,\n",
       "  1.1222625970840454,\n",
       "  2.4913923740386963,\n",
       "  -2.4240193367004395,\n",
       "  0.21378569304943085,\n",
       "  -1.1130470037460327,\n",
       "  -1.9017492532730103,\n",
       "  1.6063480377197266,\n",
       "  0.9348804950714111,\n",
       "  2.9572105407714844,\n",
       "  -1.9404038190841675,\n",
       "  -1.3578131198883057,\n",
       "  2.354585647583008,\n",
       "  -0.8630892038345337,\n",
       "  -1.353898525238037,\n",
       "  1.3397109508514404,\n",
       "  -1.9683772325515747,\n",
       "  2.8461079597473145,\n",
       "  -3.6388003826141357,\n",
       "  -2.1550536155700684,\n",
       "  -0.34200429916381836,\n",
       "  2.2147016525268555,\n",
       "  3.9500057697296143,\n",
       "  -0.2681034207344055,\n",
       "  1.0520973205566406,\n",
       "  0.7278982400894165,\n",
       "  -0.8275650143623352,\n",
       "  0.21856920421123505,\n",
       "  2.1166534423828125,\n",
       "  2.550793409347534,\n",
       "  -2.3735620975494385,\n",
       "  -4.067924499511719,\n",
       "  -0.7396605610847473,\n",
       "  3.8168506622314453,\n",
       "  -0.5998014211654663,\n",
       "  -1.2223844528198242,\n",
       "  -0.37885427474975586,\n",
       "  4.448639392852783,\n",
       "  0.28729522228240967,\n",
       "  -2.4193670749664307,\n",
       "  1.7070001363754272,\n",
       "  -0.7610052824020386,\n",
       "  1.6157541275024414,\n",
       "  0.3040930926799774,\n",
       "  -0.06329972296953201,\n",
       "  -2.501417636871338,\n",
       "  0.4101378917694092,\n",
       "  2.0292983055114746,\n",
       "  1.3073348999023438,\n",
       "  -2.112218141555786,\n",
       "  0.9522677659988403,\n",
       "  -4.140927314758301,\n",
       "  3.1871681213378906,\n",
       "  -0.9596125483512878,\n",
       "  2.0699353218078613,\n",
       "  0.24523358047008514,\n",
       "  -0.8464696407318115,\n",
       "  -0.7125105857849121,\n",
       "  2.515899658203125,\n",
       "  -0.2919691205024719,\n",
       "  1.551806092262268,\n",
       "  1.020053505897522,\n",
       "  -0.9989688992500305,\n",
       "  -2.529749631881714,\n",
       "  -1.7073073387145996,\n",
       "  -1.6135939359664917,\n",
       "  0.4203897714614868,\n",
       "  -0.8849053978919983,\n",
       "  4.115758895874023,\n",
       "  -1.9425022602081299,\n",
       "  -0.3167624771595001,\n",
       "  0.17589528858661652,\n",
       "  3.390303373336792,\n",
       "  4.729640483856201,\n",
       "  -2.004124641418457,\n",
       "  -2.255995512008667,\n",
       "  0.2562545835971832,\n",
       "  0.7738211154937744,\n",
       "  0.18883363902568817,\n",
       "  -0.4618593454360962,\n",
       "  -3.8043525218963623,\n",
       "  0.08978293836116791,\n",
       "  -3.235375165939331,\n",
       "  -0.05906178802251816,\n",
       "  -1.7469552755355835,\n",
       "  4.524702072143555,\n",
       "  -1.4748135805130005,\n",
       "  -1.2416359186172485,\n",
       "  1.560818076133728,\n",
       "  1.4411814212799072,\n",
       "  0.4890170991420746,\n",
       "  0.8876475095748901,\n",
       "  2.422049045562744,\n",
       "  -2.468928098678589,\n",
       "  0.38018798828125,\n",
       "  0.6295883655548096,\n",
       "  -2.5771195888519287,\n",
       "  1.9807778596878052],\n",
       " [2.0475800037384033,\n",
       "  2.1761581897735596,\n",
       "  -2.4525513648986816,\n",
       "  -0.02821843884885311,\n",
       "  -0.5911107063293457,\n",
       "  -2.88044810295105,\n",
       "  -1.6930164098739624,\n",
       "  0.8873878121376038,\n",
       "  5.109617233276367,\n",
       "  5.056115627288818,\n",
       "  6.250401020050049,\n",
       "  7.06860876083374,\n",
       "  -3.075601100921631,\n",
       "  4.821963787078857,\n",
       "  0.9779033064842224,\n",
       "  -1.7866050004959106,\n",
       "  1.0794768333435059,\n",
       "  -0.9036049246788025,\n",
       "  -0.8514423370361328,\n",
       "  -0.12620504200458527,\n",
       "  0.20876474678516388,\n",
       "  0.11172302812337875,\n",
       "  -5.985260009765625,\n",
       "  -0.9188838005065918,\n",
       "  0.21308790147304535,\n",
       "  -4.2267937660217285,\n",
       "  -3.5512144565582275,\n",
       "  -0.1325368583202362,\n",
       "  3.632176399230957,\n",
       "  3.517940044403076,\n",
       "  -0.322031706571579,\n",
       "  -1.219088077545166,\n",
       "  -1.3599300384521484,\n",
       "  0.690515398979187,\n",
       "  0.4505617618560791,\n",
       "  -0.14750976860523224,\n",
       "  3.3126134872436523,\n",
       "  -5.8190436363220215,\n",
       "  2.1044325828552246,\n",
       "  -0.5036156177520752,\n",
       "  -1.7510054111480713,\n",
       "  -2.537933826446533,\n",
       "  1.2743756771087646,\n",
       "  -0.9107141494750977,\n",
       "  1.0705749988555908,\n",
       "  4.231514930725098,\n",
       "  0.7669837474822998,\n",
       "  -3.5078611373901367,\n",
       "  -5.406092166900635,\n",
       "  -0.8964387774467468,\n",
       "  -8.229625701904297,\n",
       "  4.434164047241211,\n",
       "  -1.7187588214874268,\n",
       "  -1.6234990358352661,\n",
       "  -0.09929614514112473,\n",
       "  -3.8633151054382324,\n",
       "  -3.727372407913208,\n",
       "  -0.8842431306838989,\n",
       "  3.6527581214904785,\n",
       "  -0.14508378505706787,\n",
       "  -2.5040225982666016,\n",
       "  -2.5302107334136963,\n",
       "  0.01417024340480566,\n",
       "  0.6524888277053833,\n",
       "  -3.2024178504943848,\n",
       "  1.2170156240463257,\n",
       "  1.3686872720718384,\n",
       "  2.6275317668914795,\n",
       "  -4.180096626281738,\n",
       "  4.5060625076293945,\n",
       "  -2.691519021987915,\n",
       "  -3.0594210624694824,\n",
       "  -0.26620835065841675,\n",
       "  -0.9272249341011047,\n",
       "  1.3434498310089111,\n",
       "  -2.496891975402832,\n",
       "  -4.124205112457275,\n",
       "  -2.678086280822754,\n",
       "  -4.813677787780762,\n",
       "  5.039503574371338,\n",
       "  -3.3610520362854004,\n",
       "  1.1843303442001343,\n",
       "  -2.077936887741089,\n",
       "  3.472604513168335,\n",
       "  -1.6781076192855835,\n",
       "  -0.0300292931497097,\n",
       "  0.6649206280708313,\n",
       "  -4.03856086730957,\n",
       "  2.922532320022583,\n",
       "  -2.0397260189056396,\n",
       "  2.217643976211548,\n",
       "  2.450014591217041,\n",
       "  -0.2615009844303131,\n",
       "  2.215503215789795,\n",
       "  -0.646260142326355,\n",
       "  -5.598255634307861,\n",
       "  1.1857314109802246,\n",
       "  2.411897897720337,\n",
       "  -3.581789255142212,\n",
       "  -1.608764410018921],\n",
       " [2.054943084716797,\n",
       "  -0.3501589000225067,\n",
       "  0.08897148817777634,\n",
       "  1.3052513599395752,\n",
       "  -1.6577116250991821,\n",
       "  -4.5394511222839355,\n",
       "  -0.5224072337150574,\n",
       "  1.0472811460494995,\n",
       "  -3.906696319580078,\n",
       "  2.7252869606018066,\n",
       "  3.830962896347046,\n",
       "  -5.104406356811523,\n",
       "  2.7664623260498047,\n",
       "  -5.16610050201416,\n",
       "  2.735959053039551,\n",
       "  4.550203323364258,\n",
       "  1.5890523195266724,\n",
       "  3.219022750854492,\n",
       "  0.447433739900589,\n",
       "  0.8163565993309021,\n",
       "  5.003141403198242,\n",
       "  -3.7452750205993652,\n",
       "  -1.6387693881988525,\n",
       "  3.513550043106079,\n",
       "  -3.4518425464630127,\n",
       "  3.3575057983398438,\n",
       "  -2.656303644180298,\n",
       "  -0.8460859060287476,\n",
       "  -2.2122364044189453,\n",
       "  5.144878387451172,\n",
       "  -2.608976125717163,\n",
       "  3.5843706130981445,\n",
       "  0.5883368253707886,\n",
       "  1.764756441116333,\n",
       "  -0.8938469290733337,\n",
       "  4.488546371459961,\n",
       "  -2.776012659072876,\n",
       "  -1.4882087707519531,\n",
       "  3.0536117553710938,\n",
       "  -3.415067434310913,\n",
       "  -1.814361333847046,\n",
       "  5.1458516120910645,\n",
       "  1.045945405960083,\n",
       "  2.5061826705932617,\n",
       "  -2.467186212539673,\n",
       "  -3.539099931716919,\n",
       "  -8.761845588684082,\n",
       "  6.179235458374023,\n",
       "  0.8543350100517273,\n",
       "  -5.000856399536133,\n",
       "  0.45528289675712585,\n",
       "  1.3136566877365112,\n",
       "  -0.6522989273071289,\n",
       "  -2.835857629776001,\n",
       "  -3.1443159580230713,\n",
       "  2.975372076034546,\n",
       "  1.6303962469100952,\n",
       "  0.4797315299510956,\n",
       "  3.1475844383239746,\n",
       "  3.361928701400757,\n",
       "  -1.6316050291061401,\n",
       "  -0.5212404131889343,\n",
       "  1.247986912727356,\n",
       "  1.8975719213485718,\n",
       "  -0.5738388895988464,\n",
       "  -4.37082052230835,\n",
       "  -3.1467840671539307,\n",
       "  -1.7027125358581543,\n",
       "  1.1268892288208008,\n",
       "  -4.4757537841796875,\n",
       "  0.9643280506134033,\n",
       "  -2.5861127376556396,\n",
       "  0.5997202396392822,\n",
       "  0.15633951127529144,\n",
       "  3.5389766693115234,\n",
       "  2.782200336456299,\n",
       "  1.7389506101608276,\n",
       "  5.654506683349609,\n",
       "  3.5194637775421143,\n",
       "  -1.7799185514450073,\n",
       "  -0.06880506128072739,\n",
       "  5.056331157684326,\n",
       "  -3.4545819759368896,\n",
       "  0.6679942607879639,\n",
       "  -0.8848740458488464,\n",
       "  -1.814232349395752,\n",
       "  2.863417148590088,\n",
       "  -3.962491750717163,\n",
       "  -3.3404290676116943,\n",
       "  -2.170044183731079,\n",
       "  1.4984753131866455,\n",
       "  -0.11258537322282791,\n",
       "  -2.0427117347717285,\n",
       "  3.298473596572876,\n",
       "  -1.1397403478622437,\n",
       "  -2.0592079162597656,\n",
       "  4.232749938964844,\n",
       "  3.1274056434631348,\n",
       "  -0.1595950424671173,\n",
       "  3.415130376815796],\n",
       " [0.7063530683517456,\n",
       "  2.084181308746338,\n",
       "  -4.5904059410095215,\n",
       "  2.99007248878479,\n",
       "  6.60329008102417,\n",
       "  5.157083511352539,\n",
       "  -4.094119548797607,\n",
       "  -6.6622796058654785,\n",
       "  -3.697103500366211,\n",
       "  -1.7345715761184692,\n",
       "  4.347701072692871,\n",
       "  -8.236230850219727,\n",
       "  0.10982577502727509,\n",
       "  -3.0227274894714355,\n",
       "  -4.06167459487915,\n",
       "  -2.0744805335998535,\n",
       "  -2.3603909015655518,\n",
       "  -1.9062576293945312,\n",
       "  -2.596937894821167,\n",
       "  -2.2168800830841064,\n",
       "  -3.2010133266448975,\n",
       "  1.449048638343811,\n",
       "  -5.877427577972412,\n",
       "  -3.6573452949523926,\n",
       "  3.802551507949829,\n",
       "  1.0129233598709106,\n",
       "  -2.480604410171509,\n",
       "  -0.5524311661720276,\n",
       "  1.7997397184371948,\n",
       "  -2.693068027496338,\n",
       "  3.9909956455230713,\n",
       "  0.21841511130332947,\n",
       "  -5.45900821685791,\n",
       "  0.6518450379371643,\n",
       "  -0.747848391532898,\n",
       "  2.0255749225616455,\n",
       "  1.4334938526153564,\n",
       "  -3.646355152130127,\n",
       "  -8.081189155578613,\n",
       "  0.46586844325065613,\n",
       "  -1.1504148244857788,\n",
       "  -0.11264463514089584,\n",
       "  2.7817203998565674,\n",
       "  -0.9727213978767395,\n",
       "  5.927225112915039,\n",
       "  -4.763769149780273,\n",
       "  2.832059383392334,\n",
       "  -5.038496971130371,\n",
       "  -5.394667625427246,\n",
       "  -3.092060089111328,\n",
       "  8.22081470489502,\n",
       "  3.2651009559631348,\n",
       "  -3.263402223587036,\n",
       "  3.058008909225464,\n",
       "  -4.703382968902588,\n",
       "  3.254859447479248,\n",
       "  4.130982398986816,\n",
       "  1.239498257637024,\n",
       "  1.6581394672393799,\n",
       "  3.102628707885742,\n",
       "  -0.3006860315799713,\n",
       "  3.0578181743621826,\n",
       "  -3.5476276874542236,\n",
       "  -0.7542909979820251,\n",
       "  -3.9521710872650146,\n",
       "  -0.4488913118839264,\n",
       "  2.334411382675171,\n",
       "  -8.103219032287598,\n",
       "  -4.081219673156738,\n",
       "  -1.5101211071014404,\n",
       "  1.8606470823287964,\n",
       "  1.9866424798965454,\n",
       "  1.2720433473587036,\n",
       "  -0.4778776466846466,\n",
       "  3.075469732284546,\n",
       "  0.2658921480178833,\n",
       "  3.7635302543640137,\n",
       "  2.4387784004211426,\n",
       "  -3.513805389404297,\n",
       "  -0.1843736320734024,\n",
       "  0.09106303751468658,\n",
       "  4.509131908416748,\n",
       "  0.8172080516815186,\n",
       "  -3.782836675643921,\n",
       "  -0.1101996898651123,\n",
       "  -3.104273557662964,\n",
       "  -1.8906126022338867,\n",
       "  1.5262997150421143,\n",
       "  2.7771518230438232,\n",
       "  1.7952485084533691,\n",
       "  1.8929975032806396,\n",
       "  -2.203479051589966,\n",
       "  2.7644827365875244,\n",
       "  -2.9278533458709717,\n",
       "  -1.217907428741455,\n",
       "  -1.1235296726226807,\n",
       "  1.7817249298095703,\n",
       "  6.077354907989502,\n",
       "  -0.608943521976471,\n",
       "  1.357715368270874],\n",
       " [0.5625150799751282,\n",
       "  2.4398436546325684,\n",
       "  -1.1589772701263428,\n",
       "  -2.1500792503356934,\n",
       "  1.1718226671218872,\n",
       "  -2.2953641414642334,\n",
       "  1.9311833381652832,\n",
       "  -2.694514513015747,\n",
       "  -2.8907361030578613,\n",
       "  1.9641132354736328,\n",
       "  -0.39661291241645813,\n",
       "  2.166851282119751,\n",
       "  -1.2847572565078735,\n",
       "  1.0178061723709106,\n",
       "  0.26351311802864075,\n",
       "  -1.284902811050415,\n",
       "  -0.09866177290678024,\n",
       "  -0.33627763390541077,\n",
       "  1.4161781072616577,\n",
       "  4.697320938110352,\n",
       "  -2.803502082824707,\n",
       "  -5.0249457359313965,\n",
       "  -0.7301032543182373,\n",
       "  1.163447380065918,\n",
       "  0.9226160049438477,\n",
       "  1.4211980104446411,\n",
       "  0.5664950609207153,\n",
       "  -0.24491330981254578,\n",
       "  1.5769246816635132,\n",
       "  3.592912435531616,\n",
       "  -2.581669330596924,\n",
       "  -0.4257183074951172,\n",
       "  4.203858375549316,\n",
       "  -0.5313814282417297,\n",
       "  0.8871761560440063,\n",
       "  -0.46291929483413696,\n",
       "  -2.040762186050415,\n",
       "  3.16255521774292,\n",
       "  0.29891568422317505,\n",
       "  1.4473578929901123,\n",
       "  -2.0686309337615967,\n",
       "  -2.8027327060699463,\n",
       "  4.345694541931152,\n",
       "  -3.800779342651367,\n",
       "  0.9752975106239319,\n",
       "  5.345553874969482,\n",
       "  -1.9611707925796509,\n",
       "  -2.744539499282837,\n",
       "  1.6590319871902466,\n",
       "  5.683488845825195,\n",
       "  2.193495035171509,\n",
       "  -1.5371748208999634,\n",
       "  -1.4117145538330078,\n",
       "  0.3906957805156708,\n",
       "  -0.1763126701116562,\n",
       "  1.7481694221496582,\n",
       "  -3.4090983867645264,\n",
       "  -0.2332688271999359,\n",
       "  0.8023592233657837,\n",
       "  -1.144405722618103,\n",
       "  -0.5197299718856812,\n",
       "  3.026482582092285,\n",
       "  0.6616352200508118,\n",
       "  1.0822811126708984,\n",
       "  3.7075812816619873,\n",
       "  0.9680913686752319,\n",
       "  -0.08699857443571091,\n",
       "  -2.513137102127075,\n",
       "  4.152943134307861,\n",
       "  1.396125316619873,\n",
       "  -0.11470600962638855,\n",
       "  -2.3881523609161377,\n",
       "  -1.6401480436325073,\n",
       "  2.043785333633423,\n",
       "  3.7105085849761963,\n",
       "  1.5850118398666382,\n",
       "  2.7500388622283936,\n",
       "  -1.9915623664855957,\n",
       "  2.4070427417755127,\n",
       "  1.1667721271514893,\n",
       "  0.5587987899780273,\n",
       "  0.8209463357925415,\n",
       "  -0.8007616996765137,\n",
       "  2.5441184043884277,\n",
       "  -6.359049320220947,\n",
       "  -7.014418125152588,\n",
       "  -2.626826763153076,\n",
       "  1.177924633026123,\n",
       "  1.0658496618270874,\n",
       "  2.5131728649139404,\n",
       "  1.621907114982605,\n",
       "  0.8259665966033936,\n",
       "  1.0704947710037231,\n",
       "  0.282329797744751,\n",
       "  0.5529075264930725,\n",
       "  -0.8308902382850647,\n",
       "  0.1313086897134781,\n",
       "  1.0630720853805542,\n",
       "  -2.4397706985473633,\n",
       "  2.509273052215576],\n",
       " [-6.203794479370117,\n",
       "  -4.384036540985107,\n",
       "  -0.15084536373615265,\n",
       "  -3.0561647415161133,\n",
       "  -5.522089958190918,\n",
       "  -2.5529613494873047,\n",
       "  0.0819573774933815,\n",
       "  -0.3815624415874481,\n",
       "  7.346303462982178,\n",
       "  -0.5896815061569214,\n",
       "  -0.7274011969566345,\n",
       "  2.1461281776428223,\n",
       "  7.743450164794922,\n",
       "  -7.260946273803711,\n",
       "  -2.58260440826416,\n",
       "  1.9643518924713135,\n",
       "  -1.6653482913970947,\n",
       "  -1.549210786819458,\n",
       "  -9.164867401123047,\n",
       "  -2.682640552520752,\n",
       "  -1.0680103302001953,\n",
       "  0.2267688810825348,\n",
       "  6.68261194229126,\n",
       "  3.388735055923462,\n",
       "  -0.6825692057609558,\n",
       "  0.6787046194076538,\n",
       "  0.5587043762207031,\n",
       "  1.340984582901001,\n",
       "  5.810307502746582,\n",
       "  -2.6993649005889893,\n",
       "  -3.7328779697418213,\n",
       "  2.667140245437622,\n",
       "  1.7613312005996704,\n",
       "  -5.383562088012695,\n",
       "  -10.768956184387207,\n",
       "  1.494148850440979,\n",
       "  1.1699090003967285,\n",
       "  -4.462327480316162,\n",
       "  1.499284267425537,\n",
       "  3.283874034881592,\n",
       "  -8.08600902557373,\n",
       "  -2.8212766647338867,\n",
       "  5.13035774230957,\n",
       "  -1.5610487461090088,\n",
       "  -1.3850865364074707,\n",
       "  -4.2948317527771,\n",
       "  0.6272417306900024,\n",
       "  4.731185436248779,\n",
       "  3.264941453933716,\n",
       "  2.1186277866363525,\n",
       "  0.9647421836853027,\n",
       "  -6.893982410430908,\n",
       "  1.9509974718093872,\n",
       "  -0.8600364327430725,\n",
       "  2.0573127269744873,\n",
       "  -1.9033452272415161,\n",
       "  1.6638543605804443,\n",
       "  -4.521541595458984,\n",
       "  1.583300232887268,\n",
       "  -1.16356360912323,\n",
       "  -4.0865960121154785,\n",
       "  3.968717336654663,\n",
       "  -0.9116758704185486,\n",
       "  1.1581286191940308,\n",
       "  3.1594815254211426,\n",
       "  -3.7882401943206787,\n",
       "  -3.6502416133880615,\n",
       "  7.758406639099121,\n",
       "  -7.889904022216797,\n",
       "  -3.0124526023864746,\n",
       "  -3.4116110801696777,\n",
       "  -2.0755257606506348,\n",
       "  2.178924083709717,\n",
       "  -0.5177751183509827,\n",
       "  -0.8573651313781738,\n",
       "  -3.8156678676605225,\n",
       "  -6.774525165557861,\n",
       "  -3.560724973678589,\n",
       "  6.5903191566467285,\n",
       "  5.069584369659424,\n",
       "  -0.5557217597961426,\n",
       "  -0.5981643199920654,\n",
       "  1.259714126586914,\n",
       "  3.61177134513855,\n",
       "  0.5500035881996155,\n",
       "  -0.3792159855365753,\n",
       "  3.816131591796875,\n",
       "  -3.627113103866577,\n",
       "  2.8226449489593506,\n",
       "  1.4853838682174683,\n",
       "  6.32493782043457,\n",
       "  -0.6362671852111816,\n",
       "  -4.120813369750977,\n",
       "  -2.623020648956299,\n",
       "  0.2101416140794754,\n",
       "  0.7197948098182678,\n",
       "  -7.765847682952881,\n",
       "  2.2249457836151123,\n",
       "  -4.091243743896484,\n",
       "  -2.1967756748199463],\n",
       " [1.5231887102127075,\n",
       "  -0.5234177112579346,\n",
       "  0.5295066237449646,\n",
       "  0.9975441098213196,\n",
       "  -0.8511738777160645,\n",
       "  -3.0192525386810303,\n",
       "  -4.1796159744262695,\n",
       "  -3.5245444774627686,\n",
       "  -0.6838999390602112,\n",
       "  -5.366784572601318,\n",
       "  7.05504035949707,\n",
       "  3.656625270843506,\n",
       "  -1.0207046270370483,\n",
       "  -0.4196968376636505,\n",
       "  -3.7037954330444336,\n",
       "  0.5550488829612732,\n",
       "  2.4510345458984375,\n",
       "  1.8352454900741577,\n",
       "  0.6400685906410217,\n",
       "  -6.800467491149902,\n",
       "  -0.7768225073814392,\n",
       "  -3.2851791381835938,\n",
       "  -1.5451442003250122,\n",
       "  -0.18425077199935913,\n",
       "  -8.772743225097656,\n",
       "  0.48232367634773254,\n",
       "  2.7290940284729004,\n",
       "  -1.575725793838501,\n",
       "  -1.5680633783340454,\n",
       "  2.7211129665374756,\n",
       "  -1.4108465909957886,\n",
       "  -7.2046895027160645,\n",
       "  -0.5804855227470398,\n",
       "  4.60936164855957,\n",
       "  1.011597990989685,\n",
       "  -2.076786518096924,\n",
       "  -1.5917203426361084,\n",
       "  7.870248317718506,\n",
       "  -6.584338665008545,\n",
       "  -1.1790257692337036,\n",
       "  -1.2530959844589233,\n",
       "  -2.0127580165863037,\n",
       "  -0.2554784417152405,\n",
       "  1.1984970569610596,\n",
       "  -6.554997444152832,\n",
       "  -2.045408010482788,\n",
       "  -4.393199443817139,\n",
       "  -4.479365825653076,\n",
       "  -1.7464268207550049,\n",
       "  1.7931991815567017,\n",
       "  5.587939262390137,\n",
       "  -5.535882949829102,\n",
       "  -5.696792125701904,\n",
       "  3.909332752227783,\n",
       "  -2.4245762825012207,\n",
       "  3.0976927280426025,\n",
       "  3.520451307296753,\n",
       "  -5.226366996765137,\n",
       "  -1.5720831155776978,\n",
       "  4.481250762939453,\n",
       "  3.094343662261963,\n",
       "  -2.7462379932403564,\n",
       "  2.0288121700286865,\n",
       "  -8.873734474182129,\n",
       "  -0.12707777321338654,\n",
       "  -0.3613203167915344,\n",
       "  -4.049001693725586,\n",
       "  -0.26870405673980713,\n",
       "  2.4515891075134277,\n",
       "  0.8202265501022339,\n",
       "  9.051645278930664,\n",
       "  2.905578136444092,\n",
       "  -2.3279378414154053,\n",
       "  -1.441035270690918,\n",
       "  -3.053030252456665,\n",
       "  7.227241516113281,\n",
       "  -3.257164239883423,\n",
       "  0.19915397465229034,\n",
       "  -1.0803806781768799,\n",
       "  8.108083724975586,\n",
       "  6.105808734893799,\n",
       "  -4.818784713745117,\n",
       "  0.3888624310493469,\n",
       "  2.8380377292633057,\n",
       "  0.5794396996498108,\n",
       "  3.192115306854248,\n",
       "  8.386151313781738,\n",
       "  1.664668321609497,\n",
       "  -4.818719863891602,\n",
       "  3.8070974349975586,\n",
       "  2.0162172317504883,\n",
       "  1.7777912616729736,\n",
       "  1.4753828048706055,\n",
       "  -2.0741302967071533,\n",
       "  -4.1397929191589355,\n",
       "  -0.15681351721286774,\n",
       "  -2.1352336406707764,\n",
       "  -4.559118270874023,\n",
       "  5.054206371307373,\n",
       "  2.0076024532318115],\n",
       " [3.4293298721313477,\n",
       "  3.2259631156921387,\n",
       "  -4.462477207183838,\n",
       "  -0.37793877720832825,\n",
       "  -1.5799733400344849,\n",
       "  -3.2856431007385254,\n",
       "  2.5825111865997314,\n",
       "  3.0143508911132812,\n",
       "  5.132916450500488,\n",
       "  2.287806510925293,\n",
       "  5.642909049987793,\n",
       "  5.050760746002197,\n",
       "  -0.8198490738868713,\n",
       "  1.408056378364563,\n",
       "  -1.4760559797286987,\n",
       "  -1.8993557691574097,\n",
       "  3.7970621585845947,\n",
       "  -0.5278710722923279,\n",
       "  -0.7022452354431152,\n",
       "  -4.659449577331543,\n",
       "  1.045784831047058,\n",
       "  5.29263973236084,\n",
       "  1.3022361993789673,\n",
       "  1.0283418893814087,\n",
       "  5.892325401306152,\n",
       "  0.22133679687976837,\n",
       "  -2.2504029273986816,\n",
       "  1.5374220609664917,\n",
       "  -0.7578149437904358,\n",
       "  -3.7306301593780518,\n",
       "  -1.9787191152572632,\n",
       "  -3.7118794918060303,\n",
       "  -1.6906863451004028,\n",
       "  -0.9030412435531616,\n",
       "  -1.3513178825378418,\n",
       "  2.198465347290039,\n",
       "  6.283387660980225,\n",
       "  1.8344990015029907,\n",
       "  0.2885042428970337,\n",
       "  0.5080397725105286,\n",
       "  -1.417519211769104,\n",
       "  0.951429009437561,\n",
       "  2.535146951675415,\n",
       "  3.720449209213257,\n",
       "  -0.8388100862503052,\n",
       "  2.6002187728881836,\n",
       "  -0.25586646795272827,\n",
       "  0.4191926419734955,\n",
       "  1.3712856769561768,\n",
       "  3.6796867847442627,\n",
       "  -3.773754596710205,\n",
       "  2.2363228797912598,\n",
       "  0.8033945560455322,\n",
       "  -2.882650852203369,\n",
       "  -5.027497291564941,\n",
       "  -3.505098342895508,\n",
       "  1.2968544960021973,\n",
       "  0.1478186398744583,\n",
       "  2.093747615814209,\n",
       "  2.8315443992614746,\n",
       "  0.69379061460495,\n",
       "  0.1147388145327568,\n",
       "  2.971243143081665,\n",
       "  1.7206224203109741,\n",
       "  7.486950874328613,\n",
       "  7.22089958190918,\n",
       "  0.31827205419540405,\n",
       "  -1.1987756490707397,\n",
       "  -5.440824031829834,\n",
       "  4.186584949493408,\n",
       "  -5.294088363647461,\n",
       "  2.828665256500244,\n",
       "  -0.6838484406471252,\n",
       "  4.551025390625,\n",
       "  -0.5691403150558472,\n",
       "  0.2793557643890381,\n",
       "  -3.3383266925811768,\n",
       "  -4.94978141784668,\n",
       "  -1.3789483308792114,\n",
       "  4.6155314445495605,\n",
       "  5.667117595672607,\n",
       "  5.78790807723999,\n",
       "  2.6890220642089844,\n",
       "  0.5346218347549438,\n",
       "  -2.0903143882751465,\n",
       "  -4.952962398529053,\n",
       "  -0.22869156301021576,\n",
       "  -3.802321195602417,\n",
       "  2.356905221939087,\n",
       "  -1.0716524124145508,\n",
       "  2.5473082065582275,\n",
       "  0.11021214723587036,\n",
       "  -5.415092945098877,\n",
       "  1.175868034362793,\n",
       "  -0.7441611289978027,\n",
       "  -2.7607975006103516,\n",
       "  4.567647933959961,\n",
       "  -0.4419630467891693,\n",
       "  1.098150372505188,\n",
       "  -2.0756375789642334],\n",
       " [-1.8476234674453735,\n",
       "  -1.433078408241272,\n",
       "  -0.6267079710960388,\n",
       "  1.5861464738845825,\n",
       "  0.5873031616210938,\n",
       "  7.3951640129089355,\n",
       "  -6.677896976470947,\n",
       "  -3.699362277984619,\n",
       "  -1.2566227912902832,\n",
       "  -1.2273671627044678,\n",
       "  -3.501631736755371,\n",
       "  4.723255157470703,\n",
       "  2.5348989963531494,\n",
       "  3.2823972702026367,\n",
       "  2.585737705230713,\n",
       "  -2.274636745452881,\n",
       "  -5.133388519287109,\n",
       "  2.7898755073547363,\n",
       "  3.846737861633301,\n",
       "  -0.2877560257911682,\n",
       "  -4.564547061920166,\n",
       "  -1.3058000802993774,\n",
       "  0.30285608768463135,\n",
       "  -1.718040943145752,\n",
       "  -1.7698866128921509,\n",
       "  -3.4288203716278076,\n",
       "  2.907564640045166,\n",
       "  -3.568721055984497,\n",
       "  -7.561259746551514,\n",
       "  2.092045545578003,\n",
       "  2.4501922130584717,\n",
       "  2.838325023651123,\n",
       "  -0.3456847071647644,\n",
       "  4.198194980621338,\n",
       "  -4.118939399719238,\n",
       "  1.8295806646347046,\n",
       "  1.150483250617981,\n",
       "  -3.4426121711730957,\n",
       "  -0.7526432871818542,\n",
       "  -3.069237232208252,\n",
       "  -0.9537665843963623,\n",
       "  -4.938591003417969,\n",
       "  0.11482749879360199,\n",
       "  1.511966586112976,\n",
       "  3.5456366539001465,\n",
       "  -0.7310904264450073,\n",
       "  -1.2148373126983643,\n",
       "  -3.4064712524414062,\n",
       "  -3.9337565898895264,\n",
       "  -4.992264270782471,\n",
       "  -5.0823750495910645,\n",
       "  -1.4480663537979126,\n",
       "  0.9072508215904236,\n",
       "  -2.06913161277771,\n",
       "  -2.0906569957733154,\n",
       "  3.7454144954681396,\n",
       "  -4.472248077392578,\n",
       "  0.8511984348297119,\n",
       "  0.9275785088539124,\n",
       "  3.1211729049682617,\n",
       "  6.793583869934082,\n",
       "  -5.34686279296875,\n",
       "  3.4759178161621094,\n",
       "  -2.272094488143921,\n",
       "  2.734464406967163,\n",
       "  -0.5698599219322205,\n",
       "  3.315359354019165,\n",
       "  3.708956718444824,\n",
       "  -2.138390302658081,\n",
       "  -6.27908182144165,\n",
       "  -2.827777862548828,\n",
       "  -1.614081859588623,\n",
       "  -0.4548778533935547,\n",
       "  -0.5443357825279236,\n",
       "  -2.0910348892211914,\n",
       "  -0.25161150097846985,\n",
       "  -2.1592204570770264,\n",
       "  3.5018157958984375,\n",
       "  1.5655027627944946,\n",
       "  -2.296128034591675,\n",
       "  -0.39524945616722107,\n",
       "  8.260011672973633,\n",
       "  1.60740327835083,\n",
       "  -2.057318925857544,\n",
       "  -0.32899588346481323,\n",
       "  2.371105432510376,\n",
       "  -2.3806962966918945,\n",
       "  -1.3873542547225952,\n",
       "  0.3974060118198395,\n",
       "  -5.784736156463623,\n",
       "  -3.47233510017395,\n",
       "  -0.30158302187919617,\n",
       "  7.029512882232666,\n",
       "  -1.4032869338989258,\n",
       "  2.0010175704956055,\n",
       "  6.071948051452637,\n",
       "  0.43521377444267273,\n",
       "  -2.539494276046753,\n",
       "  0.23828279972076416,\n",
       "  -2.0114407539367676],\n",
       " [5.454640865325928,\n",
       "  0.41487205028533936,\n",
       "  -1.2058144807815552,\n",
       "  -1.5045894384384155,\n",
       "  3.467930793762207,\n",
       "  0.1118321493268013,\n",
       "  -0.3618238866329193,\n",
       "  -0.3269687592983246,\n",
       "  3.0147705078125,\n",
       "  -2.3504412174224854,\n",
       "  2.933142900466919,\n",
       "  -1.9843268394470215,\n",
       "  -3.7668280601501465,\n",
       "  -1.5548323392868042,\n",
       "  0.2244836837053299,\n",
       "  -0.35062167048454285,\n",
       "  -0.35355284810066223,\n",
       "  -0.6896069049835205,\n",
       "  2.140184164047241,\n",
       "  -3.9034423828125,\n",
       "  -1.7006347179412842,\n",
       "  3.2676353454589844,\n",
       "  1.9408376216888428,\n",
       "  3.5279271602630615,\n",
       "  -0.9647454619407654,\n",
       "  -5.650172710418701,\n",
       "  3.470723867416382,\n",
       "  -0.7442033290863037,\n",
       "  -0.5485963225364685,\n",
       "  2.1210410594940186,\n",
       "  1.0102638006210327,\n",
       "  2.733372449874878,\n",
       "  2.8232581615448,\n",
       "  -1.4125422239303589,\n",
       "  1.3846311569213867,\n",
       "  -3.6199216842651367,\n",
       "  -3.839942455291748,\n",
       "  0.9765324592590332,\n",
       "  3.073242664337158,\n",
       "  -0.9820907115936279,\n",
       "  -4.857109069824219,\n",
       "  -2.001704692840576,\n",
       "  0.9510493278503418,\n",
       "  0.9951639175415039,\n",
       "  1.7725324630737305,\n",
       "  1.1197104454040527,\n",
       "  1.1515955924987793,\n",
       "  -0.3875257968902588,\n",
       "  1.1255863904953003,\n",
       "  1.478935718536377,\n",
       "  -5.316202163696289,\n",
       "  1.941726803779602,\n",
       "  2.1764252185821533,\n",
       "  0.8913190960884094,\n",
       "  0.680645763874054,\n",
       "  -1.540810227394104,\n",
       "  0.2697480022907257,\n",
       "  -2.0754806995391846,\n",
       "  0.9071492552757263,\n",
       "  2.012899160385132,\n",
       "  -0.4548831880092621,\n",
       "  -1.483207106590271,\n",
       "  -0.519201397895813,\n",
       "  1.9047534465789795,\n",
       "  1.1621983051300049,\n",
       "  0.5606549978256226,\n",
       "  -0.859382152557373,\n",
       "  0.12375833839178085,\n",
       "  -3.6716320514678955,\n",
       "  3.7949471473693848,\n",
       "  -3.1703271865844727,\n",
       "  -3.5818755626678467,\n",
       "  -0.5283055901527405,\n",
       "  -4.30605936050415,\n",
       "  1.0567054748535156,\n",
       "  -1.5705758333206177,\n",
       "  1.9568681716918945,\n",
       "  4.6723222732543945,\n",
       "  -3.5409178733825684,\n",
       "  2.865041732788086,\n",
       "  -0.23835791647434235,\n",
       "  1.1714917421340942,\n",
       "  -7.043930530548096,\n",
       "  4.000320911407471,\n",
       "  -4.7374982833862305,\n",
       "  -0.24210800230503082,\n",
       "  -1.7949672937393188,\n",
       "  -0.04713102802634239,\n",
       "  -0.3679458200931549,\n",
       "  -0.3486907184123993,\n",
       "  0.5633465647697449,\n",
       "  -0.9913135170936584,\n",
       "  1.4644722938537598,\n",
       "  1.4589054584503174,\n",
       "  2.0100226402282715,\n",
       "  1.8232632875442505,\n",
       "  2.210838556289673,\n",
       "  -4.135145664215088,\n",
       "  -5.896651744842529,\n",
       "  6.056230545043945],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_train[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.9988250732421875,\n",
       " 4.592367649078369,\n",
       " 2.8691295028693276e-06,\n",
       " 8.436801726929843e-05,\n",
       " 0.0030765836127102375,\n",
       " 4.4009026169078425e-05,\n",
       " 1.4098850442678668e-06,\n",
       " 0.21443389356136322,\n",
       " 4.99976921081543,\n",
       " 4.989309787750244,\n",
       " 4.998795509338379,\n",
       " 1.0576161457720445e-06,\n",
       " 1.2819693088531494,\n",
       " 8.440025567324483e-09,\n",
       " 4.847967624664307,\n",
       " 1.4181325695972191e-06,\n",
       " 1.3359247077460168e-06,\n",
       " 4.981239318847656,\n",
       " 4.972445487976074,\n",
       " 0.06584279984235764,\n",
       " 0.7508531212806702,\n",
       " 4.999998092651367,\n",
       " 1.2617031188710826e-06,\n",
       " 1.2527779290394392e-05,\n",
       " 1.5455980246770196e-06,\n",
       " 3.783156671488541e-06,\n",
       " 2.974584049297846e-06,\n",
       " 4.997616767883301,\n",
       " 4.99953556060791,\n",
       " 4.999997138977051,\n",
       " 4.999999523162842,\n",
       " 0.00011452476610429585,\n",
       " 1.7561302456670091e-06,\n",
       " 0.0006354181095957756,\n",
       " 0.000161038275109604,\n",
       " 0.02514462172985077,\n",
       " 4.999945640563965,\n",
       " 0.16092371940612793,\n",
       " 3.783816737268353e-06,\n",
       " 0.043255798518657684,\n",
       " 4.583837509155273,\n",
       " 0.00796157494187355,\n",
       " 2.851735985132109e-07,\n",
       " 2.779670467134565e-06,\n",
       " 0.0005391387385316193,\n",
       " 9.84698417596519e-05,\n",
       " 4.9968976974487305,\n",
       " 4.999866485595703,\n",
       " 0.0012464395258575678,\n",
       " 4.997578144073486,\n",
       " 3.939923772122711e-06,\n",
       " 0.006084205117076635,\n",
       " 1.8599170446395874,\n",
       " 0.0348966009914875,\n",
       " 2.0344128870419809e-07,\n",
       " 2.950537691503996e-06,\n",
       " 9.311505664300057e-07,\n",
       " 4.999999046325684,\n",
       " 4.999905586242676,\n",
       " 0.0030566449277102947,\n",
       " 1.882799744606018,\n",
       " 0.00016041092749219388,\n",
       " 4.0013226509927335e-08,\n",
       " 4.999999523162842,\n",
       " 2.251507567052613e-06,\n",
       " 0.0019719304982572794,\n",
       " 0.003952298313379288,\n",
       " 0.22690339386463165,\n",
       " 1.807914668461308e-05,\n",
       " 4.997503280639648,\n",
       " 4.39561245002551e-06,\n",
       " 4.982303142547607,\n",
       " 8.237870474658848e-07,\n",
       " 0.13399721682071686,\n",
       " 4.972615718841553,\n",
       " 4.598906517028809,\n",
       " 2.3199713723442983e-06,\n",
       " 1.1919437383767217e-06,\n",
       " 0.12630021572113037,\n",
       " 4.9995269775390625,\n",
       " 2.556109393481165e-06,\n",
       " 4.981684014637722e-06,\n",
       " 2.918426752090454,\n",
       " 4.984293460845947,\n",
       " 0.00020530683104880154,\n",
       " 1.7939513782039285e-05,\n",
       " 0.00010370685049565509,\n",
       " 9.943229173359214e-08,\n",
       " 4.490930557250977,\n",
       " 4.966341018676758,\n",
       " 4.019110929220915e-05,\n",
       " 1.4115278190729441e-06,\n",
       " 4.73134923595353e-06,\n",
       " 4.212714195251465,\n",
       " 2.8641537141993467e-07,\n",
       " 1.713454480523069e-07,\n",
       " 3.9544079303741455,\n",
       " 1.4189995454216842e-06,\n",
       " 0.0002335463068448007,\n",
       " 2.723679542541504,\n",
       " 2.1734397411346436,\n",
       " 0.43372756242752075,\n",
       " 0.004115414340049028,\n",
       " 1.9922822713851929,\n",
       " 1.9875342331943102e-06,\n",
       " 0.18168261647224426,\n",
       " 0.026811443269252777,\n",
       " 0.6642347574234009,\n",
       " 0.007069479674100876,\n",
       " 0.11554442346096039,\n",
       " 0.11359153687953949,\n",
       " 0.03073374554514885,\n",
       " 0.003028459846973419,\n",
       " 0.35928353667259216,\n",
       " 0.004625051282346249,\n",
       " 3.2046942877173024e-09,\n",
       " 0.07581795752048492,\n",
       " 0.02476515620946884,\n",
       " 2.080958366394043,\n",
       " 4.09397443945636e-06,\n",
       " 3.079687667195685e-05,\n",
       " 0.16527661681175232,\n",
       " 0.4051920473575592,\n",
       " 0.00048519286792725325,\n",
       " 1.4607616321882233e-05,\n",
       " 0.006667790003120899,\n",
       " 0.0045585427433252335,\n",
       " 0.06491697579622269,\n",
       " 0.013602067716419697,\n",
       " 0.1395420879125595,\n",
       " 0.6564731001853943,\n",
       " 5.675168495145044e-07,\n",
       " 0.00047767042997293174,\n",
       " 4.9106268882751465,\n",
       " 0.6612486243247986,\n",
       " 0.3760026693344116,\n",
       " 0.921235978603363,\n",
       " 3.3259472846984863,\n",
       " 2.9974389690323733e-05,\n",
       " 4.267909389454871e-06,\n",
       " 0.17408280074596405,\n",
       " 0.17872008681297302,\n",
       " 0.08061911165714264,\n",
       " 3.818225741269998e-05,\n",
       " 2.5561777761140547e-07,\n",
       " 0.00030616711592301726,\n",
       " 0.009434635750949383,\n",
       " 0.038917481899261475,\n",
       " 2.565401700849179e-06,\n",
       " 2.271860012115212e-06,\n",
       " 2.9893917599110864e-06,\n",
       " 4.289654731750488,\n",
       " 0.00018776225624606013,\n",
       " 0.02024814672768116,\n",
       " 3.28348647826715e-07,\n",
       " 1.9430358122463076e-07,\n",
       " 0.003539946861565113,\n",
       " 0.009727533906698227,\n",
       " 0.502426266670227,\n",
       " 0.014586792327463627,\n",
       " 0.00981904473155737,\n",
       " 1.0494457001186674e-06,\n",
       " 4.479415110836271e-06,\n",
       " 2.328676462173462,\n",
       " 2.7679093363985885e-06,\n",
       " 0.0033774981275200844,\n",
       " 4.521271705627441,\n",
       " 0.4410213530063629,\n",
       " 0.0015539278974756598,\n",
       " 0.0015027809422463179,\n",
       " 1.5553451930827578e-06,\n",
       " 2.10230721719995e-09,\n",
       " 0.001437197090126574,\n",
       " 4.3782222292065853e-07,\n",
       " 0.0017679091542959213,\n",
       " 1.6681286069797352e-05,\n",
       " 2.010078361536216e-07,\n",
       " 0.15916910767555237,\n",
       " 4.713202201855893e-07,\n",
       " 0.42152583599090576,\n",
       " 0.06979390978813171,\n",
       " 0.42378783226013184,\n",
       " 1.0311075584468199e-06,\n",
       " 0.16793200373649597,\n",
       " 0.5112954378128052,\n",
       " 0.5978507995605469,\n",
       " 4.300837190385209e-06,\n",
       " 4.4750012762051483e-07,\n",
       " 8.558778290534974e-07,\n",
       " 0.00012963834160473198,\n",
       " 2.772371544779162e-06,\n",
       " 2.2897455416101553e-13,\n",
       " 1.8731576204299927,\n",
       " 0.0036245775409042835,\n",
       " 9.8872817488882e-07,\n",
       " 6.706187036797928e-07,\n",
       " 0.012404815293848515,\n",
       " 5.5865780751451766e-12,\n",
       " 3.2720792293548584,\n",
       " 0.00010258168185828254,\n",
       " 1.8091906309127808,\n",
       " 0.4281945526599884,\n",
       " 0.01582344062626362,\n",
       " 3.248615264892578,\n",
       " 4.991666355635971e-05,\n",
       " 1.7305457731708884e-05,\n",
       " 4.773901309818029e-07,\n",
       " 4.725858688354492,\n",
       " 1.8165621757507324,\n",
       " 2.296567916870117,\n",
       " 0.39507463574409485,\n",
       " 7.011547609181434e-07,\n",
       " 1.807980083867733e-06,\n",
       " 0.00046706965076737106,\n",
       " 1.8716492604653467e-06,\n",
       " 1.284732775275188e-06,\n",
       " 1.2551456620712997e-06,\n",
       " 0.3023209869861603,\n",
       " 0.29813483357429504,\n",
       " 0.000730516912881285,\n",
       " 8.574888852308504e-06,\n",
       " 0.11968803405761719,\n",
       " 2.6280758380889893,\n",
       " 3.401701178518124e-06,\n",
       " 3.1496063456870615e-05,\n",
       " 1.7850529729912523e-06,\n",
       " 1.7867477026811684e-06,\n",
       " 1.9906203746795654,\n",
       " 0.23062503337860107,\n",
       " 0.6722729206085205,\n",
       " 0.008984550833702087,\n",
       " 1.025458550429903e-05,\n",
       " 6.42168345166283e-07,\n",
       " 2.552795886993408,\n",
       " 0.0003183881926815957,\n",
       " 0.0011446126736700535,\n",
       " 0.38840118050575256,\n",
       " 2.8610589504241943,\n",
       " 3.142050672977348e-06,\n",
       " 8.35957416711608e-06,\n",
       " 1.162375610874733e-05,\n",
       " 1.9756752252578735,\n",
       " 2.5010696845129132e-05,\n",
       " 1.3535645848605782e-06,\n",
       " 1.9021681509912014e-06,\n",
       " 4.925678730010986,\n",
       " 2.9191933208494447e-06,\n",
       " 3.875415802001953,\n",
       " 0.06042741611599922,\n",
       " 0.039434805512428284,\n",
       " 0.0013548375573009253,\n",
       " 0.11191900819540024,\n",
       " 8.559095476812217e-06,\n",
       " 1.2141032129875384e-05,\n",
       " 9.886528005154105e-07,\n",
       " 3.0969005138103967e-07,\n",
       " 2.4135388798640633e-07,\n",
       " 4.713243007659912,\n",
       " 2.683854108909145e-05,\n",
       " 1.8875799361051104e-12,\n",
       " 0.0007270874921232462,\n",
       " 1.789554880815558e-05,\n",
       " 4.5526132907980355e-07,\n",
       " 3.306688070297241,\n",
       " 1.42163287364383e-06,\n",
       " 1.078437662727083e-06,\n",
       " 0.7813515663146973,\n",
       " 5.713388304684486e-07,\n",
       " 1.4796364307403564,\n",
       " 0.09146754443645477,\n",
       " 5.4251700021268334e-06,\n",
       " 2.478484702805872e-06,\n",
       " 2.607359647299745e-06,\n",
       " 1.2042522534727595e-09,\n",
       " 0.05053324997425079,\n",
       " 2.0171050891804043e-06,\n",
       " 6.45696331957879e-07,\n",
       " 1.532165356366022e-06,\n",
       " 7.691555765632074e-07,\n",
       " 4.592374801635742,\n",
       " 0.00038551725447177887,\n",
       " 0.002248745411634445,\n",
       " 3.955454417337023e-07,\n",
       " 1.9088041369741404e-07,\n",
       " 0.1792769432067871,\n",
       " 1.4628050327301025,\n",
       " 3.3232803344726562,\n",
       " 6.777670205337927e-05,\n",
       " 2.7755447717936477e-08,\n",
       " 0.7343159914016724,\n",
       " 0.015166462399065495,\n",
       " 7.715991614531958e-07,\n",
       " 0.025717811658978462,\n",
       " 1.3561667401518207e-05,\n",
       " 5.266789457891718e-07,\n",
       " 6.968698016862618e-06,\n",
       " 2.5462141036987305,\n",
       " 2.4889847127784748e-11,\n",
       " 3.8852405548095703,\n",
       " 4.475552558898926,\n",
       " 0.09030460566282272,\n",
       " 3.092475526500493e-05,\n",
       " 6.330023552436614e-06,\n",
       " 0.0005688023520633578,\n",
       " 0.0007120560621842742,\n",
       " 0.0047456081956624985,\n",
       " 6.79297720504457e-12,\n",
       " 4.294073104858398,\n",
       " 0.7216213941574097,\n",
       " 0.356730580329895,\n",
       " 0.00015853640798013657,\n",
       " 5.805334078040625e-12,\n",
       " 0.13853004574775696,\n",
       " 3.0784602131461725e-05,\n",
       " 0.057160090655088425,\n",
       " 2.377963277677697e-13,\n",
       " 0.03459164500236511,\n",
       " 2.3766829144733492e-06,\n",
       " 6.295663479249924e-05,\n",
       " 0.01895451545715332,\n",
       " 2.1148878204257926e-09,\n",
       " 0.001447542104870081,\n",
       " 4.5673346519470215,\n",
       " 3.938902981559522e-09,\n",
       " 1.8695494645726285e-06,\n",
       " 8.814821702424203e-13,\n",
       " 1.8751510651782155e-05,\n",
       " 0.003215521341189742,\n",
       " 0.01739475689828396,\n",
       " 0.1386837363243103,\n",
       " 0.8803896903991699,\n",
       " 0.014752400107681751,\n",
       " 2.259654269254341e-12,\n",
       " 0.034628838300704956,\n",
       " 0.0004235762753523886,\n",
       " 0.00011958161485381424,\n",
       " 0.00018927922064904124,\n",
       " 0.3019722104072571,\n",
       " 2.2738538518751739e-07,\n",
       " 7.501660661546339e-07,\n",
       " 0.10797092318534851,\n",
       " 0.022562937811017036,\n",
       " 0.00048378424253314734,\n",
       " 0.0013402976328507066,\n",
       " 0.004323502536863089,\n",
       " 0.002042160602286458,\n",
       " 3.6789489968214184e-05,\n",
       " 4.19471206214439e-07,\n",
       " 1.4067258834838867,\n",
       " 4.358304067864083e-06,\n",
       " 2.297184664712404e-06,\n",
       " 0.011505060829222202,\n",
       " 1.1870113212353317e-06,\n",
       " 0.0005417753709480166,\n",
       " 1.1045428891520714e-06,\n",
       " 0.013002580031752586,\n",
       " 0.002395489253103733,\n",
       " 0.00015248671115841717,\n",
       " 0.3477519154548645,\n",
       " 7.568814908154309e-07,\n",
       " 0.7734601497650146,\n",
       " 2.94570661196758e-08,\n",
       " 5.3103402024134994e-05,\n",
       " 1.5044846534729004,\n",
       " 8.705465006642044e-07,\n",
       " 0.00038340772152878344,\n",
       " 0.00028864556225016713,\n",
       " 0.005542970262467861,\n",
       " 2.1126841595608958e-11,\n",
       " 1.1034815088351024e-06,\n",
       " 0.000171928753843531,\n",
       " 0.0011595238465815783,\n",
       " 7.576855568913743e-05,\n",
       " 0.00019449432147666812,\n",
       " 6.961404341865318e-09,\n",
       " 3.32174778350236e-07,\n",
       " 3.001925152901208e-09,\n",
       " 0.001059101545251906,\n",
       " 7.544693971794914e-07,\n",
       " 0.027307430282235146,\n",
       " 2.1450121494126506e-05,\n",
       " 0.1289626806974411,\n",
       " 0.0008166528423316777,\n",
       " 4.433198773767799e-05,\n",
       " 1.4838207107459311e-06,\n",
       " 8.374295248358976e-07,\n",
       " 0.012469799257814884,\n",
       " 0.06262025982141495,\n",
       " 1.8039792848867364e-05,\n",
       " 1.2128607806971559e-07,\n",
       " 8.185927630188772e-12,\n",
       " 7.837110024411231e-05,\n",
       " 0.0009538530721329153,\n",
       " 1.1124418506369693e-06,\n",
       " 1.6585943285463145e-06,\n",
       " 0.03469628095626831,\n",
       " 0.08595715463161469,\n",
       " 1.4426641428144649e-05,\n",
       " 0.08166976273059845,\n",
       " 5.382039489632007e-07,\n",
       " 2.481278896331787,\n",
       " 0.005026181228458881,\n",
       " 5.244195335762925e-07,\n",
       " 7.037942277576814e-13,\n",
       " 3.484070930426242e-06,\n",
       " 4.239730969857192e-06,\n",
       " 5.674032355074132e-09,\n",
       " 4.2135725021362305,\n",
       " 2.77970552444458,\n",
       " 0.00366751616820693,\n",
       " 0.03687566518783569,\n",
       " 3.1393219614983536e-06,\n",
       " 0.0005943308351561427,\n",
       " 0.0005326275713741779,\n",
       " 1.2122865200581145e-06,\n",
       " 1.0754443407058716,\n",
       " 3.004204750061035,\n",
       " 4.0146780122540804e-08,\n",
       " 6.877978648844874e-07,\n",
       " 1.1861294169079883e-09,\n",
       " 2.3772854262915644e-07,\n",
       " 0.13792234659194946,\n",
       " 1.0412768125534058,\n",
       " 4.194746907160152e-06,\n",
       " 3.6878345781587996e-06,\n",
       " 1.1285773098279606e-06,\n",
       " 9.671359748608666e-07,\n",
       " 0.009073709137737751,\n",
       " 0.05504833161830902,\n",
       " 0.02695772983133793,\n",
       " 1.2178539426921375e-11,\n",
       " 6.712444928780315e-07,\n",
       " 1.3115982255840208e-06,\n",
       " 0.2983230650424957,\n",
       " 1.9456467725831317e-06,\n",
       " 7.792142469043029e-07,\n",
       " 0.0420365147292614,\n",
       " 0.022680247202515602,\n",
       " 0.0071463617496192455,\n",
       " 0.0001872538705356419,\n",
       " 2.1936220946372487e-06,\n",
       " 0.00031691629556007683,\n",
       " 3.1845379453443456e-06,\n",
       " 2.4000334705731596e-11,\n",
       " 0.01356838271021843,\n",
       " 0.015663111582398415,\n",
       " 9.965070057660341e-05,\n",
       " 0.04179227352142334,\n",
       " 0.00041390699334442616,\n",
       " 1.4035649655852467e-05,\n",
       " 0.015802394598722458,\n",
       " 1.7660274806985399e-06,\n",
       " 1.2641841067306814e-06,\n",
       " 6.551908427354647e-06,\n",
       " 8.169366765287123e-07,\n",
       " 3.878801351220318e-07,\n",
       " 1.0902724266052246,\n",
       " 0.018608275800943375,\n",
       " 3.5716586112976074,\n",
       " 2.404732640570728e-06,\n",
       " 1.348824980595964e-06,\n",
       " 1.7291680705966428e-05,\n",
       " 4.193023414700292e-06,\n",
       " 0.10428809374570847,\n",
       " 2.4883642368855874e-10,\n",
       " 1.6986782611638773e-06,\n",
       " 0.00032503262627869844,\n",
       " 3.403505388632766e-06,\n",
       " 0.0071389200165867805,\n",
       " 2.9220260330475867e-05,\n",
       " 6.066837840990047e-07,\n",
       " 0.0932510495185852,\n",
       " 0.008938288316130638,\n",
       " 3.4376989788142964e-06,\n",
       " 7.633198606527003e-07,\n",
       " 2.3919195513144587e-09,\n",
       " 6.56506585983152e-07,\n",
       " 1.0275471140630543e-06,\n",
       " 1.1368410923751071e-06,\n",
       " 0.063908651471138,\n",
       " 6.781911565667542e-07,\n",
       " 3.1030913305585273e-06,\n",
       " 1.976770590772503e-06,\n",
       " 1.812181835703086e-05,\n",
       " 5.1254237405373715e-06,\n",
       " 1.2543318916868884e-06,\n",
       " 0.0008469277527183294,\n",
       " 5.36787142513262e-11,\n",
       " 6.05094099825898e-13,\n",
       " 2.7503885576152243e-05,\n",
       " 2.804992618621327e-06,\n",
       " 2.2232241462916136e-05,\n",
       " 1.0428699397380115e-06,\n",
       " 7.288318738574162e-05,\n",
       " 9.92696413959493e-07,\n",
       " 1.8109640176344755e-10,\n",
       " 5.048269144936057e-07,\n",
       " 3.9344990909739863e-07,\n",
       " 0.006084213964641094,\n",
       " 2.3482363076254842e-07,\n",
       " 1.304080605506897,\n",
       " 0.01299775205552578,\n",
       " 5.36905131465204e-10,\n",
       " 6.979038857934938e-07,\n",
       " 2.34529352383106e-06,\n",
       " 1.7457506373830256e-06,\n",
       " 2.858243533410132e-06,\n",
       " 0.09676206856966019,\n",
       " 0.20808395743370056,\n",
       " 6.724735612806398e-06,\n",
       " 0.00045687099918723106,\n",
       " 3.5456792829791084e-05,\n",
       " 2.538448597988463e-06,\n",
       " 4.1946692363126203e-05,\n",
       " 4.079988846772409e-10,\n",
       " 1.5939064041958773e-06,\n",
       " 4.223326868668664e-06,\n",
       " 7.084375829435885e-05,\n",
       " 1.6630599930067547e-05,\n",
       " 1.7169962802654481e-06,\n",
       " 1.4528665133184404e-06,\n",
       " 0.002192987594753504,\n",
       " 0.1919364184141159,\n",
       " 1.2198883325709176e-07,\n",
       " 3.7467489164555445e-06,\n",
       " 1.284560084968689e-06,\n",
       " 1.2056750042788167e-09,\n",
       " 2.9876850931032095e-06,\n",
       " 2.404251020493575e-09,\n",
       " 1.799463643692434e-05,\n",
       " 2.988015239679953e-06,\n",
       " 1.0272923418597202e-06,\n",
       " 3.608299266488757e-06,\n",
       " 0.0026306810323148966,\n",
       " 5.479887931869598e-06,\n",
       " 1.6406097529397812e-06,\n",
       " 1.613801759958733e-05,\n",
       " 0.015039556659758091,\n",
       " 1.986941015275079e-06,\n",
       " 8.421025654570258e-07,\n",
       " 3.6649958019552287e-06,\n",
       " 1.0414642019895837e-05,\n",
       " 4.514014108281117e-06,\n",
       " 1.1005651003870298e-06,\n",
       " 1.4536190064973198e-06,\n",
       " 5.9467020037118345e-05,\n",
       " 4.773389719048282e-06,\n",
       " 0.0002566193579696119,\n",
       " 0.005852890200912952,\n",
       " 2.2780169217639923e-07,\n",
       " 8.196344651878462e-07,\n",
       " 6.163052148622228e-07,\n",
       " 4.265952156856656e-06,\n",
       " 3.5010178783823065e-11,\n",
       " 2.9856141736672726e-06,\n",
       " 1.8348357571085216e-06,\n",
       " 2.2738945484161377,\n",
       " 0.00012345972936600447,\n",
       " 0.06490607559680939,\n",
       " 1.2943511137564201e-05,\n",
       " 4.20164639081122e-07,\n",
       " 2.851526915037539e-06,\n",
       " 0.026444721966981888,\n",
       " 0.019986994564533234,\n",
       " 2.0898241928080097e-06,\n",
       " 4.244006959197577e-06,\n",
       " 3.707205905811861e-05,\n",
       " 1.4787775626246003e-06,\n",
       " 1.8178764094045619e-06,\n",
       " 4.131934929318959e-06,\n",
       " 0.008803160861134529,\n",
       " 2.8711854611174203e-05,\n",
       " 2.6255170268996153e-06,\n",
       " 1.0315708323105355e-06,\n",
       " 1.686523319222033e-06,\n",
       " 5.290772264743282e-07,\n",
       " 1.482489892623562e-06,\n",
       " 1.2101438642275752e-06,\n",
       " 4.233977051626425e-06,\n",
       " 7.318155257962644e-05,\n",
       " 2.180392812078935e-06,\n",
       " 0.00017665131599642336,\n",
       " 2.040204890363384e-06,\n",
       " 2.545143615861889e-07,\n",
       " 1.988275471376255e-06,\n",
       " 1.7334011772618396e-06,\n",
       " 0.00731428898870945,\n",
       " 1.2098321349185426e-06,\n",
       " 9.828092970565194e-07,\n",
       " 1.5006369835646183e-07,\n",
       " 3.882978944602655e-06,\n",
       " 1.9566350317745673e-08,\n",
       " 7.108190402504988e-06,\n",
       " 3.15910170911593e-07,\n",
       " 4.847008199249103e-07,\n",
       " 1.3227855788500165e-06,\n",
       " 4.4174353206472006e-06,\n",
       " 1.6325453771059983e-06,\n",
       " 0.0003970259858760983,\n",
       " 0.0010574829066172242,\n",
       " 0.07831938564777374,\n",
       " 0.0016504268860444427,\n",
       " 5.859066010138747e-11,\n",
       " 0.00024336767091881484,\n",
       " 0.00025057257153093815,\n",
       " 1.2829814988180033e-09,\n",
       " 1.1330638649553748e-08,\n",
       " 0.004143837373703718,\n",
       " 0.0021526110358536243,\n",
       " 5.421471541922074e-06,\n",
       " 0.06829297542572021,\n",
       " 5.397354925662512e-06,\n",
       " 2.13921771319292e-06,\n",
       " 3.925936553628162e-08,\n",
       " 2.7840824259328656e-06,\n",
       " 0.06486765295267105,\n",
       " 1.9930594419292902e-07,\n",
       " 1.6481985767313745e-06,\n",
       " 5.534894626180176e-06,\n",
       " 7.902369247858587e-07,\n",
       " 3.4941821658307504e-10,\n",
       " 1.7027913372658077e-06,\n",
       " 0.8520258665084839,\n",
       " 1.0991575436491985e-06,\n",
       " 5.708418737704335e-10,\n",
       " 6.90025728999899e-07,\n",
       " 1.2353953025012743e-06,\n",
       " 4.690475634561153e-06,\n",
       " 9.421203230886022e-07,\n",
       " 7.814155651431065e-06,\n",
       " 2.484212302533706e-08,\n",
       " 1.828751123866823e-06,\n",
       " 7.936687893561611e-07,\n",
       " 2.9833852750016376e-05,\n",
       " 5.040079486207105e-05,\n",
       " 2.0929276161041344e-06,\n",
       " 1.9672845610330114e-06,\n",
       " 0.045818254351615906,\n",
       " 1.1565258546397672e-06,\n",
       " 7.703587812102342e-07,\n",
       " 3.7477743717317935e-06,\n",
       " 0.00012353097554296255,\n",
       " 5.158666681381874e-06,\n",
       " 1.1942941569031973e-07,\n",
       " 1.9602355223469203e-06,\n",
       " 0.0002842724206857383,\n",
       " 1.415268229720823e-06,\n",
       " 0.0034070340916514397,\n",
       " 8.717660421098117e-06,\n",
       " 3.613961098380969e-06,\n",
       " 4.450795131560881e-06,\n",
       " 6.950373062863946e-06,\n",
       " 4.671774604503298e-06,\n",
       " 4.7451038653889555e-08,\n",
       " 7.822760039744026e-07,\n",
       " 1.4723325421073241e-06,\n",
       " 0.053305260837078094,\n",
       " 5.997589141770732e-06,\n",
       " 0.39720475673675537,\n",
       " 2.060780389001593e-06,\n",
       " 1.0402829708766603e-09,\n",
       " 1.978121488832585e-08,\n",
       " 5.208187758398708e-06,\n",
       " 0.009456560015678406,\n",
       " 1.5190144040388986e-06,\n",
       " 1.8033370352554812e-09,\n",
       " 9.362043783767149e-06,\n",
       " 0.006455046124756336,\n",
       " 2.8299134555709315e-06,\n",
       " 7.824916679055605e-07,\n",
       " 3.596230726543581e-06,\n",
       " 1.7603473452254548e-06,\n",
       " 1.3010699149162974e-06,\n",
       " 1.832609541452257e-06,\n",
       " 6.108589900577499e-08,\n",
       " 1.1975072311543045e-06,\n",
       " 1.6114031220482161e-09,\n",
       " 1.9237111246184213e-06,\n",
       " 2.2066396923037246e-06,\n",
       " 0.024325910955667496,\n",
       " 3.50971959051094e-06,\n",
       " 4.957867531629745e-06,\n",
       " 5.162039684591946e-09,\n",
       " 1.2763869108312065e-06,\n",
       " 5.89365117775742e-06,\n",
       " 3.316353968330077e-06,\n",
       " 0.34371092915534973,\n",
       " 3.821627160505159e-06,\n",
       " 4.688136414188193e-06,\n",
       " 2.987576635860023e-06,\n",
       " 2.7748474167310633e-06,\n",
       " 1.6155397588590859e-06,\n",
       " 1.0975276154567837e-06,\n",
       " 1.203321318143935e-07,\n",
       " 1.1666496675388771e-06,\n",
       " 6.423820764211996e-07,\n",
       " 5.292359219311038e-06,\n",
       " 1.028704218697385e-06,\n",
       " 6.51961329367623e-07,\n",
       " 0.0014430349692702293,\n",
       " 6.988614040892571e-05,\n",
       " 8.463979952466616e-07,\n",
       " 3.828565908747805e-09,\n",
       " 1.4154868495097617e-06,\n",
       " 5.0228678446728736e-05,\n",
       " 7.823066425771685e-07,\n",
       " 4.131639030902079e-08,\n",
       " 3.553892611307674e-06,\n",
       " 1.0428998997724648e-08,\n",
       " 1.128426352359213e-09,\n",
       " 1.4665782146039419e-05,\n",
       " 1.2094620416291946e-08,\n",
       " 1.758109499996885e-12,\n",
       " 8.973723311100912e-07,\n",
       " 1.8492670506020659e-06,\n",
       " 8.056249498622492e-05,\n",
       " 2.0036608475493267e-05,\n",
       " 5.620046067633666e-06,\n",
       " 1.1134426358694327e-06,\n",
       " 2.9294367323018378e-06,\n",
       " 2.166734930142411e-06,\n",
       " 9.889450893751928e-07,\n",
       " 2.0840318029513583e-05,\n",
       " 3.375261181659539e-11,\n",
       " 2.1295903707141406e-08,\n",
       " 1.7677580217423383e-06,\n",
       " 3.6592086871678475e-06,\n",
       " 1.6195578211863904e-07,\n",
       " 2.614824836655316e-07,\n",
       " 3.0858770969643956e-06,\n",
       " 3.4455399600119563e-06,\n",
       " 8.850477684063662e-07,\n",
       " 2.568598574725911e-06,\n",
       " 3.6753706744718784e-09,\n",
       " 6.3687225519970525e-06,\n",
       " 1.7678185031400062e-06,\n",
       " 7.1438757913711015e-06,\n",
       " 3.3384558264515363e-06,\n",
       " 3.997599560406906e-12,\n",
       " 1.5287076848835568e-06,\n",
       " 1.5132899306991021e-06,\n",
       " 9.301166414843465e-07,\n",
       " 2.1435635062516667e-06,\n",
       " 1.5531203416685457e-06,\n",
       " 1.5585478649882134e-06,\n",
       " 1.9469116097070582e-08,\n",
       " 2.032308884736267e-06,\n",
       " 2.4485539142915513e-06,\n",
       " 4.029765477753244e-06,\n",
       " 9.967081950890133e-07,\n",
       " 2.14313422475243e-06,\n",
       " 4.649115908250678e-06,\n",
       " 1.2605087249539793e-06,\n",
       " 4.56633051726385e-06,\n",
       " 1.2289488040551078e-06,\n",
       " 9.375895615448826e-07,\n",
       " 9.732396574690938e-05,\n",
       " 9.279707668952142e-09,\n",
       " 9.172382124233991e-05,\n",
       " 1.59818353040464e-06,\n",
       " 6.444012257134091e-08,\n",
       " 6.294200829870533e-06,\n",
       " 3.168575091194725e-08,\n",
       " 4.426544364832807e-06,\n",
       " 2.2628460882856416e-08,\n",
       " 2.4681369268364506e-06,\n",
       " 3.3542175970069366e-06,\n",
       " 2.5086642381211277e-06,\n",
       " 1.3388947728287803e-09,\n",
       " 5.763158128502255e-08,\n",
       " 2.7382857297197916e-06,\n",
       " 1.2621025007319986e-06,\n",
       " 7.596463388881425e-12,\n",
       " 1.369372284898418e-06,\n",
       " 6.340451363939792e-06,\n",
       " 1.21817970466509e-06,\n",
       " 2.0451893650852426e-11,\n",
       " 2.6366706151748076e-06,\n",
       " 1.0581730975900427e-06,\n",
       " 1.0149779882340226e-05,\n",
       " 1.8690770957618952e-06,\n",
       " 1.0897783370156233e-10,\n",
       " 2.2159206309879664e-06,\n",
       " 1.59980396985393e-11,\n",
       " 1.95664188140654e-06,\n",
       " 1.2341176898189588e-06,\n",
       " 5.247244189376943e-06,\n",
       " 1.435508806935104e-06,\n",
       " 2.7820201466965955e-06,\n",
       " 2.8746123537093382e-11,\n",
       " 1.6751966995798284e-06,\n",
       " 4.4842081159401914e-09,\n",
       " 2.2764186269341735e-06,\n",
       " 9.95290605487753e-08,\n",
       " 2.638889554873458e-06,\n",
       " 3.540699026416405e-06,\n",
       " 3.189175458828686e-06,\n",
       " 9.91278947815033e-10,\n",
       " 6.066400715099007e-10,\n",
       " 4.4301188495410315e-07,\n",
       " 1.6103852973348154e-10,\n",
       " 1.1534012855918263e-08,\n",
       " 1.1851073455915184e-09,\n",
       " 2.6874049652292342e-09,\n",
       " 2.3371751467493596e-06,\n",
       " 3.54206349584274e-06,\n",
       " 3.066900717385579e-06,\n",
       " 3.1218683034239803e-06,\n",
       " 4.027215450008725e-09,\n",
       " 9.687994406704092e-07,\n",
       " 1.6250102135018096e-06,\n",
       " 3.65404412150383e-06,\n",
       " 2.7523344670044025e-06,\n",
       " 3.0302253435365856e-06,\n",
       " 1.8878634211461076e-09,\n",
       " 2.1216269487922546e-06,\n",
       " 5.474589531706542e-11,\n",
       " 2.7072380817116937e-06,\n",
       " 1.828273298087879e-06,\n",
       " 3.969325916841626e-06,\n",
       " 1.1577154737096862e-06,\n",
       " 2.7506314381753327e-06,\n",
       " 3.7497766243177466e-06,\n",
       " 3.416666686462122e-06,\n",
       " 2.677540805962053e-06,\n",
       " 1.670917413321149e-06,\n",
       " 1.8391081990642988e-09,\n",
       " 3.84601025871234e-06,\n",
       " 3.952297447540332e-06,\n",
       " 1.421173465132597e-06,\n",
       " 2.2818614979769336e-06,\n",
       " 1.5950606666592648e-06,\n",
       " 1.5206347825369448e-06,\n",
       " 6.248464342206717e-05,\n",
       " 1.7467334523235678e-10,\n",
       " 1.0925608648904017e-06,\n",
       " 3.591716449591331e-06,\n",
       " 8.467055522487499e-06,\n",
       " 2.041154402832035e-06,\n",
       " 3.211017656212789e-06,\n",
       " 1.3603390698335716e-06,\n",
       " 3.8648292388643313e-07,\n",
       " 1.81500786311517e-06,\n",
       " 1.8655955500435084e-06,\n",
       " 9.331275805379846e-07,\n",
       " 1.113749590331281e-06,\n",
       " 2.608421482364065e-06,\n",
       " 0.00014587903569918126,\n",
       " 4.753691882797284e-06,\n",
       " 7.410885245917598e-06,\n",
       " 3.320610403534374e-06,\n",
       " 1.2163152405264555e-06,\n",
       " 1.766229615896009e-06,\n",
       " 2.742726337601198e-06,\n",
       " 2.313590584890335e-06,\n",
       " 6.601304676223663e-07,\n",
       " 3.799322030317853e-06,\n",
       " 2.0122188288951293e-06,\n",
       " 1.5546823988188407e-06,\n",
       " 2.2391188903014836e-10,\n",
       " 2.270631739520468e-06,\n",
       " 1.8609329117680318e-06,\n",
       " 1.1278382316959323e-06,\n",
       " 2.3335846588423692e-09,\n",
       " 2.6210941541648936e-06,\n",
       " 2.2694953258906025e-06,\n",
       " 2.0085265077796066e-06,\n",
       " 2.5441656816838076e-06,\n",
       " 1.5672660538257333e-06,\n",
       " 2.4174714781111106e-06,\n",
       " 1.2246268852322828e-06,\n",
       " 1.5452164916496258e-06,\n",
       " 1.4403165096155135e-06,\n",
       " 9.904646276481799e-07,\n",
       " 4.295361122785835e-06,\n",
       " 3.616436288211844e-06,\n",
       " 2.472523647156777e-06,\n",
       " 1.3832669765179162e-06,\n",
       " 2.670089997991454e-06,\n",
       " 7.159219421737362e-07,\n",
       " 1.5559476196358446e-06,\n",
       " 4.259687102603493e-06,\n",
       " 1.6977242012217175e-06,\n",
       " 8.831414675114502e-07,\n",
       " 1.2702532785624499e-06,\n",
       " 6.1432674556272104e-06,\n",
       " 2.5064546207431704e-06,\n",
       " 2.648512690939242e-06,\n",
       " 1.6616007769698626e-06,\n",
       " 5.255487849353813e-06,\n",
       " 2.4621704142191447e-06,\n",
       " 2.2243029889068566e-06,\n",
       " 1.1681651130857063e-06,\n",
       " 3.303106495877728e-06,\n",
       " 1.1464625231383252e-06,\n",
       " 1.5218766975522158e-06,\n",
       " 2.2022352368367137e-06,\n",
       " 1.6393414625781588e-06,\n",
       " 1.4476177057076711e-06,\n",
       " 2.5140050183836138e-06,\n",
       " 2.510918875486823e-06,\n",
       " 1.9425820028118324e-06,\n",
       " 1.8885859844886e-06,\n",
       " 2.409549097137642e-06,\n",
       " 1.298058236898214e-06,\n",
       " 1.991634462683578e-06,\n",
       " 1.3934687785877031e-06,\n",
       " 1.8723972061707173e-06,\n",
       " 1.0040570259661763e-06,\n",
       " 1.5653585023756023e-06,\n",
       " 2.3588013391417917e-06,\n",
       " 1.455304300179705e-06,\n",
       " 3.892937911587069e-06,\n",
       " 1.2015727861580672e-06,\n",
       " 1.7047949540938134e-06,\n",
       " 1.7886724208437954e-06,\n",
       " 6.191978627612116e-07,\n",
       " 1.6717431208235212e-06,\n",
       " 1.955886318683042e-06,\n",
       " 4.25684856963926e-06,\n",
       " 2.015801328525413e-06,\n",
       " 2.140011247320217e-06,\n",
       " 1.0829879784068908e-06,\n",
       " 1.1950053249165649e-06,\n",
       " 1.004213117994368e-06,\n",
       " 2.002247811105917e-06,\n",
       " 1.083436245608027e-06,\n",
       " 9.036940582518582e-07,\n",
       " 1.666164280322846e-06,\n",
       " 1.6726696685509523e-06,\n",
       " 4.239880581735633e-06,\n",
       " 1.826506263569172e-06,\n",
       " 1.2314665127632907e-06,\n",
       " 1.7773290892364457e-06,\n",
       " 1.8019329672824824e-06,\n",
       " 1.6897158729989314e-06,\n",
       " 1.441656195311225e-06,\n",
       " 2.112680704158265e-06,\n",
       " 1.3879659945814637e-06,\n",
       " 1.126783558902389e-06,\n",
       " 2.252497552035493e-06,\n",
       " 1.284704580939433e-06,\n",
       " 1.49872380461602e-06,\n",
       " 1.6638762190268608e-06,\n",
       " 3.2204266062763054e-06,\n",
       " 1.3261658295959933e-06,\n",
       " 1.8614405234984588e-06,\n",
       " 6.765329771951656e-07,\n",
       " 1.244864961336134e-06,\n",
       " 2.928721642092569e-06,\n",
       " 2.6200793854513904e-06,\n",
       " 2.1978419226797996e-06,\n",
       " 1.4701690815854818e-06,\n",
       " 1.567511162647861e-06,\n",
       " 1.3608243989438051e-06,\n",
       " 1.17216575290513e-06,\n",
       " 1.2510417946032248e-06,\n",
       " 2.4925884645199403e-06,\n",
       " 3.514127001835732e-06,\n",
       " 2.5593999453121796e-06,\n",
       " 1.918950829349342e-06,\n",
       " 1.4470131191046676e-06,\n",
       " 2.6771783723233966e-06,\n",
       " 2.499200718375505e-06,\n",
       " 2.2100239220890217e-06,\n",
       " 1.327983227383811e-06,\n",
       " 2.0446323105716147e-06,\n",
       " 1.7707072856865125e-06,\n",
       " 4.5741280700895e-06,\n",
       " 1.93794858205365e-06,\n",
       " 7.086753157636849e-07,\n",
       " 1.2504727919804282e-06,\n",
       " 1.6706799215171486e-06,\n",
       " 1.0197150004387368e-06,\n",
       " 1.3148519428796135e-06,\n",
       " 2.9012144295847975e-06,\n",
       " 2.6300454010197427e-06,\n",
       " 1.595013600308448e-06,\n",
       " 1.7124876876550843e-06,\n",
       " 2.320110752407345e-06,\n",
       " 2.4448158910672646e-06,\n",
       " 1.9973540474893525e-06,\n",
       " 2.703592372199637e-06,\n",
       " 1.916375822474947e-06,\n",
       " 2.4002765712793916e-06,\n",
       " 1.8148953131458256e-06,\n",
       " 4.538207576842979e-06,\n",
       " 7.862325333007902e-07,\n",
       " 1.4425172594201285e-06,\n",
       " 1.9333190266479505e-06,\n",
       " 3.091541657340713e-06,\n",
       " 1.5090788565430557e-06,\n",
       " 8.546388698960072e-07,\n",
       " 2.048512214969378e-06,\n",
       " 2.101660129483207e-06,\n",
       " 1.4777822343603475e-06,\n",
       " 3.771499450522242e-06,\n",
       " 1.5643615824956214e-06,\n",
       " 4.984746055924916e-07,\n",
       " 2.170784455302055e-06]"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_decoded[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated...\n",
      "what did the arctica robbin sherriff the the the his town robbin robbin robbin robbin \n",
      "===========================\n",
      "Generated...\n",
      "why did the papsmear robbin footrace earl's to somehow the somehow robbin robbin robbin robbin \n",
      "===========================\n",
      "Generated...\n",
      "what do you call a accross sherriff a the the the robbin robbin robbin robbin \n",
      "===========================\n",
      "Generated...\n",
      "how many jews does it spike to dared a the 15yo robbin robbin robbin robbin \n",
      "===========================\n",
      "Generated...\n",
      "why is the portugal pokemon so because because crusades robbin somehow robbin robbin robbin robbin \n",
      "===========================\n",
      "Generated...\n",
      "i just convince a portugal camaro somehow somehow just somehow somehow robbin robbin robbin robbin \n",
      "===========================\n",
      "Generated...\n",
      "i used to bowling a the another the arctica the castle robbin robbin robbin robbin \n",
      "===========================\n",
      "Generated...\n",
      "i just knew this monopoly whose camaro camaro littleknown a somehow robbin robbin robbin robbin \n",
      "===========================\n",
      "Generated...\n",
      "what does panzer a minigolf a and a the a the robbin robbin robbin robbin \n",
      "===========================\n",
      "Generated...\n",
      "why wasnt the cholo kick the the the marrow somehow somehow robbin robbin robbin robbin \n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(padded_sentences):\n",
    "#     print(\"Original...\")\n",
    "#     print_sentence_with_w2v(sentence)\n",
    "    print(\"Generated...\")\n",
    "    print_sentence_with_w2v(sent_decoded[i])\n",
    "    print(\"===========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder trained above embeds sentences (concatenated word vetors) into a lower dimensional space. The code below takes two of these lower dimensional sentence representations and finds five points between them. It then uses the trained decoder to project these five points into the higher, original, dimensional space. Finally, it reveals the text represented by the five generated sentence vectors by taking each word vector concatenated inside and finding the text associated with it in the word2vec used during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_hom = shortest_homology(sent_encoded[3], sent_encoded[10], 5)\n",
    "for point in test_hom:\n",
    "    p = generator.predict(np.array([point]))[0]\n",
    "    print_sentence_with_w2v(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below does the same thing, with one important difference. After sampling equidistant points in the latent space between two sentence embeddings, it finds the embeddings from our encoded dataset those points are most similar to. It then prints the text associated with those vectors.\n",
    "  \n",
    "This allows us to explore how the Variational Autoencoder clusters our dataset of sentences in latent space. It lets us investigate whether sentences with similar concepts or grammatical styles are represented in similar areas of the lower dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_hom = shortest_homology(sent_encoded[2], sent_encoded[1500], 20)\n",
    "for point in test_hom:\n",
    "    p = generator.predict(np.array([find_similar_encoding(point)]))[0]\n",
    "    print_sentence_with_w2v(p)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
