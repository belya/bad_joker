{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from scipy.stats import norm\n",
    "import nltk.data\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import reuters\n",
    "from nltk. corpus import gutenberg\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.layers import Input, Dense, Lambda, Layer, LSTM, Reshape, TimeDistributed, Dropout, Bidirectional, RepeatVector, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import gensim.downloader as api\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing code is data specific.  \n",
    "  \n",
    "It is an example of how one can use a pre-trained word2vec to embed sentences into a vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO train w2v model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = api.load('20-newsgroups')\n",
    "# info = api.info()  # show info about available models/datasets\n",
    "# word2vec_model = api.load(\"glove-twitter-100\")  # download the model and return as object ready for use\n",
    "# word2vec_model.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"shortjokes.csv\").set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = pd.read_csv(\"jokes_score_name_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1[\"Joke\"] = dataset_1[\"q\"] + \" \" + dataset_1[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = pd.read_csv(\"qajokes1.1.2.csv\")\n",
    "dataset_2[\"Joke\"] = dataset_2[\"Question\"] + \" \" + dataset_2[\"Answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = dataset[\"Joke\"].tolist() + dataset_1[\"Joke\"].tolist() + dataset_2[\"Joke\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return re.sub(\n",
    "        r\"[^\\w\\s']\", \n",
    "        \"\", \n",
    "        text\n",
    "    ).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_sentences = [preprocess_text(t) for t in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440099"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model = Word2Vec(preprocessed_sentences, size=100, window=10, workers=16, iter=100)\n",
    "# w2v_model = word2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phelps', 0.5148839950561523),\n",
       " (\"bolt's\", 0.5110259056091309),\n",
       " ('bloodbath', 0.45941269397735596),\n",
       " ('gust', 0.4141930341720581),\n",
       " ('nada', 0.4051152169704437),\n",
       " ('glimpse', 0.40208110213279724),\n",
       " ('key', 0.3946117162704468),\n",
       " ('ricocheted', 0.39381635189056396),\n",
       " ('lightning', 0.38503432273864746),\n",
       " ('binos', 0.38127273321151733)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"bolt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = w2v_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing text from a variety of different sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 45000., 233729., 105550.,  20059.,   4429.,   2733.,   2216.,\n",
       "          2010.,   1910.,   1746.]),\n",
       " array([  1. ,  10.9,  20.8,  30.7,  40.6,  50.5,  60.4,  70.3,  80.2,\n",
       "         90.1, 100. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) + 1 for s in preprocessed_sentences if len(s) < 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No LSTM variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_sentences = [preprocess_text(t) for t in dataset_2[\"Joke\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = 1000\n",
    "original_dims = (1000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence(sentence):\n",
    "    concat_vector = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            concat_vector.append(w2v[word])\n",
    "        except:\n",
    "            return\n",
    "    return [a for vector in concat_vector for a in vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_sentences = [sentence for sentence in preprocessed_sentences if (len(sentence) < 10) & (len(sentence) > 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sentences = [vectorize_sentence(sentence) for sentence in preprocessed_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sentences = [sentence for sentence in vectorized_sentences if sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "vectorized_padded = sequence.pad_sequences(vectorized_sentences, maxlen=original_dim, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_vectorized_padded = (vectorized_padded - vectorized_padded.min()) / (vectorized_padded.max() - vectorized_padded.min())# + 0.01*np.random.randn(*normalized_vectorized_padded.shape)\n",
    "normalized_vectorized_padded = vectorized_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618af7a408b040bbab6f4a716ab0c84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41807), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weights_masks = np.array([[1.] * (len(sentence) * 100) + [0] * (original_dim - len(sentence) * 100) for sentence in tqdm_notebook(preprocessed_sentences)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_sentences = [preprocess_text(t) for t in dataset_2[\"Joke\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence(sentence):\n",
    "    concat_vector = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            concat_vector.append(w2v[word])\n",
    "        except:\n",
    "            return\n",
    "    return concat_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sentences = [vectorize_sentence(sentence) for sentence in preprocessed_sentences if (len(sentence) < 20) & (len(sentence) > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sentences = [sentence for sentence in vectorized_sentences if sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_padded = np.array([sentence + [[0] * 100] * (20 - len(sentence)) for sentence in vectorized_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_vectorized_padded = (vectorized_padded - vectorized_padded.min()) / (vectorized_padded.max() - vectorized_padded.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dims = (20, 100)\n",
    "original_dim = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to shuffle the text vectors before splitting them into test and train samples.   \n",
    "  \n",
    "This is done to avoid clumping text with similar context and style in the dataset because it can confuse the neural network during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = ShuffleSplit(n_splits=3)\n",
    "train_indices, test_indices = next(split.split(normalized_vectorized_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train = normalized_vectorized_padded[train_indices]\n",
    "vectorized_test = normalized_vectorized_padded[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights_masks = weights_masks[train_indices]\n",
    "test_weights_masks = weights_masks[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "def cut_dataset(dataset, batch_size):\n",
    "    rest = len(dataset) % batch_size\n",
    "    return dataset[:-rest]\n",
    "\n",
    "vectorized_train = cut_dataset(vectorized_train, batch_size)\n",
    "vectorized_test = cut_dataset(vectorized_test, batch_size)\n",
    "train_weights_masks = cut_dataset(train_weights_masks, batch_size)\n",
    "test_weights_masks = cut_dataset(test_weights_masks, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_vectorized_train = vectorized_train.reshape(-1, original_dim)\n",
    "help_vectorized_test = vectorized_test.reshape(-1, original_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get w2v embeddings for text with fixed length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Values are normalized for sigmoid - done\n",
    "2. LSTM usage in encoder - done\n",
    "3. LSTM usage in decoder - done (without Flatten - not done)\n",
    "4. Layers dropout - not done, underfitting\n",
    "5. Tokens instead of word2vec vectors? Or use something instead of binary crossentropy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary crossentropy for non binary values?!\n",
    "\n",
    "Use something that can replace E[log P(X|z)]\n",
    "\n",
    "Why cross-entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "lstm_dim = 100\n",
    "intermediate_dim = 1000\n",
    "epochs = 200\n",
    "epsilon_std = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=original_dims)\n",
    "weights_mask = Input(shape=original_dims)\n",
    "h = Dropout(0.2)(x)\n",
    "h = Dense(intermediate_dim, activation='relu')(h)\n",
    "h_mean = Dense(intermediate_dim, activation='relu')(h)\n",
    "z_mean = Dense(latent_dim)(h_mean)\n",
    "h_log_var = Dense(intermediate_dim, activation='relu')(h)\n",
    "z_log_var = Dense(latent_dim)(h_log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h_1 = Dense(intermediate_dim, activation='relu')\n",
    "decoder_h_2 = Dense(intermediate_dim, activation='relu')\n",
    "decoder_h_3 = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='linear') \n",
    "\n",
    "h_decoded = decoder_h_1(z)\n",
    "h_decoded = decoder_h_2(h_decoded)\n",
    "h_decoded = decoder_h_3(h_decoded)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def xent_loss(y_true, y_pred):\n",
    "# #     return K.sum(K.binary_crossentropy(y_true, y_pred), axis=1)\n",
    "#     return original_dim * K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "# def kl_loss(y_true, y_pred):\n",
    "# #     return 0.5 * K.sum(K.square(z_mean) + K.exp(z_log_var) - 1. - z_log_var, axis=1)\n",
    "#     return - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "\n",
    "# def vae_loss(y_true, y_pred):\n",
    "# #     return xent_loss(y_true, y_pred) + kl_loss(y_true, y_pred)\n",
    "#     return K.mean(xent_loss(y_true, y_pred) + kl_loss(y_true, y_pred))\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "#     xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "    xent_loss = original_dim * metrics.mean_squared_error(x * weights_mask, x_decoded_mean * weights_mask)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return K.mean(xent_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = Model([x, weights_mask], x_decoded_mean)\n",
    "vae.compile(optimizer='adam', loss=vae_loss, metrics=[\"mse\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vae.predict(vectorized_train, batch_size=batch_size) - vectorized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 3000 samples\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 15s 520us/step - loss: 2007.6319 - mean_squared_error: 2.2629 - acc: 0.5499 - val_loss: 1900.9103 - val_mean_squared_error: 2.1582 - val_acc: 0.5817\n",
      "\n",
      "Epoch 00001: saving model to /tmp/model.h5\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 5s 173us/step - loss: 1764.2944 - mean_squared_error: 2.0408 - acc: 0.5826 - val_loss: 1880.3573 - val_mean_squared_error: 2.1503 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00002: saving model to /tmp/model.h5\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 5s 175us/step - loss: 1754.2659 - mean_squared_error: 2.0341 - acc: 0.5814 - val_loss: 1875.4743 - val_mean_squared_error: 2.1430 - val_acc: 0.5847\n",
      "\n",
      "Epoch 00003: saving model to /tmp/model.h5\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 5s 176us/step - loss: 1750.4319 - mean_squared_error: 2.0306 - acc: 0.5838 - val_loss: 1875.0781 - val_mean_squared_error: 2.1417 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00004: saving model to /tmp/model.h5\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 5s 172us/step - loss: 1747.2569 - mean_squared_error: 2.0276 - acc: 0.5842 - val_loss: 1872.9382 - val_mean_squared_error: 2.1389 - val_acc: 0.5797\n",
      "\n",
      "Epoch 00005: saving model to /tmp/model.h5\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 5s 171us/step - loss: 1744.9366 - mean_squared_error: 2.0250 - acc: 0.5831 - val_loss: 1868.2243 - val_mean_squared_error: 2.1355 - val_acc: 0.5840\n",
      "\n",
      "Epoch 00006: saving model to /tmp/model.h5\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 5s 171us/step - loss: 1741.6614 - mean_squared_error: 2.0210 - acc: 0.5866 - val_loss: 1867.8170 - val_mean_squared_error: 2.1327 - val_acc: 0.5893\n",
      "\n",
      "Epoch 00007: saving model to /tmp/model.h5\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 5s 172us/step - loss: 1740.2781 - mean_squared_error: 2.0190 - acc: 0.5861 - val_loss: 1866.6387 - val_mean_squared_error: 2.1297 - val_acc: 0.5823\n",
      "\n",
      "Epoch 00008: saving model to /tmp/model.h5\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 5s 170us/step - loss: 1735.8937 - mean_squared_error: 2.0146 - acc: 0.5864 - val_loss: 1866.3934 - val_mean_squared_error: 2.1351 - val_acc: 0.5787\n",
      "\n",
      "Epoch 00009: saving model to /tmp/model.h5\n",
      "Epoch 10/200\n",
      "28000/28000 [==============================] - 5s 169us/step - loss: 1734.0336 - mean_squared_error: 2.0118 - acc: 0.5817 - val_loss: 1863.9939 - val_mean_squared_error: 2.1305 - val_acc: 0.5873\n",
      "\n",
      "Epoch 00010: saving model to /tmp/model.h5\n",
      "Epoch 11/200\n",
      "28000/28000 [==============================] - 5s 169us/step - loss: 1730.9685 - mean_squared_error: 2.0079 - acc: 0.5815 - val_loss: 1861.0692 - val_mean_squared_error: 2.1236 - val_acc: 0.5850\n",
      "\n",
      "Epoch 00011: saving model to /tmp/model.h5\n",
      "Epoch 12/200\n",
      "28000/28000 [==============================] - 5s 168us/step - loss: 1728.1725 - mean_squared_error: 2.0051 - acc: 0.5827 - val_loss: 1858.8299 - val_mean_squared_error: 2.1208 - val_acc: 0.5943\n",
      "\n",
      "Epoch 00012: saving model to /tmp/model.h5\n",
      "Epoch 13/200\n",
      "28000/28000 [==============================] - 5s 169us/step - loss: 1723.4108 - mean_squared_error: 2.0003 - acc: 0.5878 - val_loss: 1860.4743 - val_mean_squared_error: 2.1231 - val_acc: 0.5777\n",
      "\n",
      "Epoch 00013: saving model to /tmp/model.h5\n",
      "Epoch 14/200\n",
      "28000/28000 [==============================] - 5s 167us/step - loss: 1722.2765 - mean_squared_error: 1.9980 - acc: 0.5819 - val_loss: 1855.5340 - val_mean_squared_error: 2.1205 - val_acc: 0.5960\n",
      "\n",
      "Epoch 00014: saving model to /tmp/model.h5\n",
      "Epoch 15/200\n",
      "28000/28000 [==============================] - 5s 165us/step - loss: 1719.7880 - mean_squared_error: 1.9948 - acc: 0.5865 - val_loss: 1855.6379 - val_mean_squared_error: 2.1169 - val_acc: 0.5683\n",
      "\n",
      "Epoch 00015: saving model to /tmp/model.h5\n",
      "Epoch 16/200\n",
      "28000/28000 [==============================] - 5s 164us/step - loss: 1717.2528 - mean_squared_error: 1.9920 - acc: 0.5837 - val_loss: 1855.1454 - val_mean_squared_error: 2.1155 - val_acc: 0.5843\n",
      "\n",
      "Epoch 00016: saving model to /tmp/model.h5\n",
      "Epoch 17/200\n",
      "28000/28000 [==============================] - 5s 165us/step - loss: 1714.2328 - mean_squared_error: 1.9876 - acc: 0.5837 - val_loss: 1852.6985 - val_mean_squared_error: 2.1130 - val_acc: 0.5767\n",
      "\n",
      "Epoch 00017: saving model to /tmp/model.h5\n",
      "Epoch 18/200\n",
      "26500/28000 [===========================>..] - ETA: 0s - loss: 1711.7998 - mean_squared_error: 1.9851 - acc: 0.5831"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1036-3798d75b5d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvectorized_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_weights_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp_vectorized_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         callbacks=cp)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### checkpoint\n",
    "cp = [callbacks.ModelCheckpoint(filepath=\"/tmp/model.h5\", verbose=1)]\n",
    "\n",
    "#train\n",
    "vae.fit([vectorized_train, train_weights_masks], help_vectorized_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=([vectorized_test, test_weights_masks], help_vectorized_test),\n",
    "        callbacks=cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "def weighted(y):\n",
    "    return y * weights_mask\n",
    "\n",
    "# build a generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=( latent_dim,))\n",
    "_h_decoded = decoder_h_1(decoder_input)\n",
    "_h_decoded = decoder_h_2(_h_decoded)\n",
    "_h_decoded = decoder_h_3(_h_decoded)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "_x_decoded_mean = Lambda(weighted, output_shape=(original_dim,))(_x_decoded_mean)\n",
    "generator = Model([decoder_input, weights_mask], _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.3315232, 3.1993313)"
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = Model(x, z_mean)\n",
    "np.min(test_model.predict(vectorized_test[0:10])), np.max(test_model.predict(vectorized_test[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text From Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some matrix magic\n",
    "def sent_parse(sentence, mat_shape):\n",
    "    data_concat = []\n",
    "    word_vecs = vectorize_sentences(sentence)\n",
    "    for x in word_vecs:\n",
    "        data_concat.append(list(itertools.chain.from_iterable(x)))\n",
    "    zero_matr = np.zeros(mat_shape)\n",
    "    zero_matr[0] = np.array(data_concat)\n",
    "    return zero_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentence_with_w2v(sent_vect):\n",
    "#     sent_vect = sent_vect * (vectorized_padded.max() - vectorized_padded.min()) + vectorized_padded.min()\n",
    "    word_sent = ''\n",
    "    tocut = sent_vect\n",
    "    for i in range (int(len(sent_vect)/100)):\n",
    "        word_sent += w2v.most_similar(positive=[tocut[:100]], topn=1)[0][0]\n",
    "        word_sent += ' '\n",
    "        tocut = tocut[100:]\n",
    "    print(word_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: encoded sentence vector\n",
    "# output: encoded sentence vector in dataset with highest cosine similarity\n",
    "def find_similar_encoding(sent_vect):\n",
    "    all_cosine = []\n",
    "    for sent in sent_encoded:\n",
    "        result = 1 - spatial.distance.cosine(sent_vect, sent)\n",
    "        all_cosine.append(result)\n",
    "    data_array = np.array(all_cosine)\n",
    "    maximum = data_array.argsort()[-3:][::-1][1]\n",
    "    new_vec = sent_encoded[maximum]\n",
    "    return new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: two points, integer n\n",
    "# output: n equidistant points on the line between the input points (inclusive)\n",
    "def shortest_homology(point_one, point_two, num):\n",
    "    dist_vec = point_two - point_one\n",
    "    sample = np.linspace(0, 1, num, endpoint = True)\n",
    "    hom_sample = []\n",
    "    for s in sample:\n",
    "        hom_sample.append(point_one + s * dist_vec)\n",
    "    return hom_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: two written sentences, VAE batch-size, dimension of VAE input\n",
    "# output: the function embeds the sentences in latent-space, and then prints their generated text representations\n",
    "# along with the text representations of several points in between them\n",
    "def sent_2_sent(sent1,sent2, batch, dim):\n",
    "    a = sent_parse([sent1], (batch,dim))\n",
    "    b = sent_parse([sent2], (batch,dim))\n",
    "    encode_a = encoder.predict(a, batch_size = batch)\n",
    "    encode_b = encoder.predict(b, batch_size = batch)\n",
    "    test_hom = hom_shortest(encode_a[0], encode_b[0], 5)\n",
    "    \n",
    "    for point in test_hom:\n",
    "        p = generator.predict(np.array([point]))[0]\n",
    "        print_sentence(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing sentences from the training set and comparing them with the original will test whether the custom print function works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [vectorize_sentence(preprocess_text(\"who are you to be here\"))]\n",
    "# padded_sentences = sequence.pad_sequences(sentences, maxlen=original_dim, padding=\"post\", truncating=\"post\")\n",
    "padded_sentences = vectorized_test[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder takes the training set of sentence vectors (concatenanted word vectors) and embeds them into a lower dimensional vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_encoded = encoder.predict(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 1092,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder takes the list of latent dimensional encodings from above and turns them back into vectors of their original dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_decoded = generator.predict([sent_encoded, test_weights_masks[0:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original...\n",
      "what do you call a gay tramp hobosexual the the \n",
      "Generated...\n",
      "what do you call a gay dinosaur a snowblower the \n",
      "===========================\n",
      "Original...\n",
      "why don't lobsters like to share they're shellfish the the \n",
      "Generated...\n",
      "why don't men like to share they're shellfish shellfish the \n",
      "===========================\n",
      "Original...\n",
      "what do you call a poor stripper ugly the the \n",
      "Generated...\n",
      "what do you call a fat woman ugly brothel the \n",
      "===========================\n",
      "Original...\n",
      "how to keep a reader in suspense removed the the \n",
      "Generated...\n",
      "how to keep a reader in it selected the the \n",
      "===========================\n",
      "Original...\n",
      "i put the p in pants the the the the \n",
      "Generated...\n",
      "i put the it in nose the the the the \n",
      "===========================\n",
      "Original...\n",
      "what is et short for he's got little legs the \n",
      "Generated...\n",
      "what is et short for he's the the the the \n",
      "===========================\n",
      "Original...\n",
      "what did silver say to gold au the the the \n",
      "Generated...\n",
      "what did 0 say to stripes waiter the the the \n",
      "===========================\n",
      "Original...\n",
      "what borders obesity mexico and canada the the the the \n",
      "Generated...\n",
      "what trump economic canada the mexico canada shipping the the \n",
      "===========================\n",
      "Original...\n",
      "so i was looking around for some vacuum the the \n",
      "Generated...\n",
      "so i was walking out for your subreddit the the \n",
      "===========================\n",
      "Original...\n",
      "what do they do to dead scientists they barium the \n",
      "Generated...\n",
      "what do they do to dead people they the the \n",
      "===========================\n",
      "Original...\n",
      "what do they call soda in rome pope the the \n",
      "Generated...\n",
      "what do they call it in syria the the the \n",
      "===========================\n",
      "Original...\n",
      "a communist joke isn't funny unless everyone gets it the \n",
      "Generated...\n",
      "a jokes joke isn't funny unless everyone gets the the \n",
      "===========================\n",
      "Original...\n",
      "what's a fresh vegetable one that insults a farmer the \n",
      "Generated...\n",
      "what's a alqaeda's bee one that eat a dog the \n",
      "===========================\n",
      "Original...\n",
      "what's a masturbator's favorite type of weather jackit weather the \n",
      "Generated...\n",
      "what's a alqaeda's favorite type of steroid inbred reason the \n",
      "===========================\n",
      "Original...\n",
      "what is the proudest body part the veins the the \n",
      "Generated...\n",
      "what is the best body mutation the the the the \n",
      "===========================\n",
      "Original...\n",
      "two men walk into a bar knock knock the the \n",
      "Generated...\n",
      "two men walk into a bar knock knock ducks the \n",
      "===========================\n",
      "Original...\n",
      "what do you call batman who skips church christian the \n",
      "Generated...\n",
      "what do you call someone who loves them skulls the \n",
      "===========================\n",
      "Original...\n",
      "i'm a people person but from a distance the the \n",
      "Generated...\n",
      "i'm a people person but on a bar bigotry the \n",
      "===========================\n",
      "Original...\n",
      "what do you call a disabled lego an o the \n",
      "Generated...\n",
      "what do you call a sick fart the the the \n",
      "===========================\n",
      "Original...\n",
      "how do you address a monster very politely the the \n",
      "Generated...\n",
      "how do you use a burrito advisor the the the \n",
      "===========================\n",
      "Original...\n",
      "you can't spell ducking without autocorrect the the the the \n",
      "Generated...\n",
      "you can't spell pepsi without it swollen commonly the the \n",
      "===========================\n",
      "Original...\n",
      "in soviet russia light turns you on the the the \n",
      "Generated...\n",
      "in soviet russia coffin runs you through waterproof faceup the \n",
      "===========================\n",
      "Original...\n",
      "dark chocolate tastes like chocolate that started doing crossfit the \n",
      "Generated...\n",
      "it fish tastes like cthulhu that was fine jellyfish the \n",
      "===========================\n",
      "Original...\n",
      "knock knock who's there to to who to whom the \n",
      "Generated...\n",
      "knock knock who's there to to who to whom the \n",
      "===========================\n",
      "Original...\n",
      "a man walks into a bar ouch the the the \n",
      "Generated...\n",
      "a man walks into a bar the the the the \n",
      "===========================\n",
      "Original...\n",
      "what's the most remarkable invention a whiteboard the the the \n",
      "Generated...\n",
      "what's the most knowledgeable fundamental a website the the the \n",
      "===========================\n",
      "Original...\n",
      "what is a ghost's favorite wild west town tombstone the \n",
      "Generated...\n",
      "what is a alqaeda's favorite philadelphia local town hat the \n",
      "===========================\n",
      "Original...\n",
      "what would mlk be if he was alive white the \n",
      "Generated...\n",
      "what would people be if he was lucky dick the \n",
      "===========================\n",
      "Original...\n",
      "how to stop pedophilia worldwide kill all the children the \n",
      "Generated...\n",
      "how to stop clickbait europeans kill felons the the the \n",
      "===========================\n",
      "Original...\n",
      "what do you call jokes about bread buns the the \n",
      "Generated...\n",
      "what do you call jokes about bread bread peanuts the \n",
      "===========================\n",
      "Original...\n",
      "what was the burglar doing at wayne manor robin the \n",
      "Generated...\n",
      "what was the dog doing at the the the the \n",
      "===========================\n",
      "Original...\n",
      "sexual assault its a touchy subject the the the the \n",
      "Generated...\n",
      "jokes actually is a funny jokes good rough submitted the \n",
      "===========================\n",
      "Original...\n",
      "what's the difference between reddit and 9gag a week the \n",
      "Generated...\n",
      "what's the difference between reddit and the the the the \n",
      "===========================\n",
      "Original...\n",
      "who doesn't do kegels a lazy cunt the the the \n",
      "Generated...\n",
      "who doesn't do infinitely a funny cunt the the the \n",
      "===========================\n",
      "Original...\n",
      "what's an emo's favourite laptop a razer blade the the \n",
      "Generated...\n",
      "what's an angolan favorite laptop a the the the the \n",
      "===========================\n",
      "Original...\n",
      "one minute without you feels like 60 seconds the the \n",
      "Generated...\n",
      "this week without you smells like twelve it upped the \n",
      "===========================\n",
      "Original...\n",
      "what do mexicans use to slice pizza little caesers the \n",
      "Generated...\n",
      "what do mexicans use to pizza the the the the \n",
      "===========================\n",
      "Original...\n",
      "what do you call a blind hooker free the the \n",
      "Generated...\n",
      "what do you call a blind man the the the \n",
      "===========================\n",
      "Original...\n",
      "how does a mathematician get to work he derives the \n",
      "Generated...\n",
      "how does a man get to work he chairlift the \n",
      "===========================\n",
      "Original...\n",
      "shin a device for finding furniture in the dark the \n",
      "Generated...\n",
      "curves a time for most heads in the the the \n",
      "===========================\n",
      "Original...\n",
      "what did russia say to ukraine crimea river the the \n",
      "Generated...\n",
      "what did muslims say to mecca jews river geese the \n",
      "===========================\n",
      "Original...\n",
      "what is the most fascist letter not c the the \n",
      "Generated...\n",
      "what is the most popular joke not criticism submitted the \n",
      "===========================\n",
      "Original...\n",
      "what is adam johnson's favourite kill streak predator missile the \n",
      "Generated...\n",
      "what is jesus clinton's favourite kill soldiers a bear the \n",
      "===========================\n",
      "Original...\n",
      "what is the most expensive type of prostitute whoreganic the \n",
      "Generated...\n",
      "what is the most expensive type the the the the \n",
      "===========================\n",
      "Original...\n",
      "how do you make a hormone don't pay her the \n",
      "Generated...\n",
      "how do you make a hormone don't pay her the \n",
      "===========================\n",
      "Original...\n",
      "what's the number one cause of dry skin towels the \n",
      "Generated...\n",
      "what's the number one cause of moist breasts stomachs the \n",
      "===========================\n",
      "Original...\n",
      "where did timmy go after the explosion everywhere the the \n",
      "Generated...\n",
      "where did sally go after the explosion everywhere subscribers the \n",
      "===========================\n",
      "Original...\n",
      "why don't sharks eat clowns because they taste funny the \n",
      "Generated...\n",
      "why don't cannibals eat clowns because the the the the \n",
      "===========================\n",
      "Original...\n",
      "describe yourself in 1 word not stupid the the the \n",
      "Generated...\n",
      "describe yourself in three words not stupid edge sixoffender the \n",
      "===========================\n",
      "Original...\n",
      "only females will get this pregnant the the the the \n",
      "Generated...\n",
      "only people will get this pregnant the the the the \n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(sent_decoded):\n",
    "    print(\"Original...\")\n",
    "    print_sentence_with_w2v(padded_sentences[i])\n",
    "    print(\"Generated...\")\n",
    "    print_sentence_with_w2v(sentence)\n",
    "    print(\"===========================\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
